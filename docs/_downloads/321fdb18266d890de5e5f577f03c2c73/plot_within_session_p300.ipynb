{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Within Session P300\n\n\nThis Example shows how to perform a within session analysis on three different\nP300 datasets.\n\nWe will compare two pipelines :\n\n- Riemannian Geometry\n- xDawn with Linear Discriminant Analysis\n\nWe will use the P300 paradigm, which uses the AUC as metric.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Pedro Rodrigues <pedro.rodrigues01@gmail.com>\n#\n# License: BSD (3-clause)\n\n# getting rid of the warnings about the future (on s'en fout !)\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom pyriemann.tangentspace import TangentSpace\nfrom pyriemann.estimation import XdawnCovariances, Xdawn\nfrom moabb.evaluations import WithinSessionEvaluation\nfrom moabb.paradigms import P300\nfrom moabb.datasets import EPFLP300\nimport moabb\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=RuntimeWarning)\n\n\nmoabb.set_log_level('info')\n\n# This is an auxiliary transformer that allows one to vectorize data\n# structures in a pipeline For instance, in the case of a X with dimensions\n# Nt x Nc x Ns, one might be interested in a new data structure with\n# dimensions Nt x (Nc.Ns)\n\n\nclass Vectorizer(BaseEstimator, TransformerMixin):\n\n    def __init__(self):\n        pass\n\n    def fit(self, X, y):\n        \"\"\"fit.\"\"\"\n        return self\n\n    def transform(self, X):\n        \"\"\"transform. \"\"\"\n        return np.reshape(X, (X.shape[0], -1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create pipelines\n----------------\n\nPipelines must be a dict of sklearn pipeline transformer.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipelines = {}\n\n# we have to do this because the classes are called 'Target' and 'NonTarget'\n# but the evaluation function uses a LabelEncoder, transforming them\n# to 0 and 1\nlabels_dict = {'Target': 1, 'NonTarget': 0}\n\npipelines['RG + LDA'] = make_pipeline(\n    XdawnCovariances(\n        nfilter=2,\n        classes=[\n            labels_dict['Target']],\n        estimator='lwf',\n        xdawn_estimator='lwf'),\n    TangentSpace(),\n    LDA(solver='lsqr', shrinkage='auto'))\n\npipelines['Xdw + LDA'] = make_pipeline(Xdawn(nfilter=2, estimator='lwf'),\n                                       Vectorizer(), LDA(solver='lsqr',\n                                                         shrinkage='auto'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluation\n----------\n\nWe define the paradigm (P300) and use all three datasets available for it.\nThe evaluation will return a dataframe containing a single AUC score for\neach subject / session of the dataset, and for each pipeline.\n\nResults are saved into the database, so that if you add a new pipeline, it\nwill not run again the evaluation unless a parameter has changed. Results can\nbe overwritten if necessary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "paradigm = P300(resample=128)\ndataset = EPFLP300()\ndataset.subject_list = dataset.subject_list[:2]\ndatasets = [dataset]\noverwrite = True  # set to True if we want to overwrite cached results\nevaluation = WithinSessionEvaluation(paradigm=paradigm,\n                                     datasets=datasets,\n                                     suffix='examples', overwrite=overwrite)\nresults = evaluation.process(pipelines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot Results\n----------------\n\nHere we plot the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(facecolor='white', figsize=[8, 4])\n\nsns.stripplot(data=results, y='score', x='pipeline', ax=ax, jitter=True,\n              alpha=.5, zorder=1, palette=\"Set1\")\nsns.pointplot(data=results, y='score', x='pipeline', ax=ax,\n              zorder=1, palette=\"Set1\")\n\nax.set_ylabel('ROC AUC')\nax.set_ylim(0.5, 1)\n\nfig.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}