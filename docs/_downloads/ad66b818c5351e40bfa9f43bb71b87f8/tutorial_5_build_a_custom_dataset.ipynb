{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Tutorial 5: Creating a dataset class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Gregoire Cattan\n#\n# https://github.com/plcrodrigues/Workshop-MOABB-BCI-Graz-2019\n\nfrom pyriemann.classification import MDM\nfrom pyriemann.estimation import ERPCovariances\nfrom sklearn.pipeline import make_pipeline\n\nfrom moabb.datasets import VirtualReality\nfrom moabb.datasets.braininvaders import bi2014a\nfrom moabb.datasets.compound_dataset import CompoundDataset\nfrom moabb.datasets.utils import blocks_reps\nfrom moabb.evaluations import WithinSessionEvaluation\nfrom moabb.paradigms.p300 import P300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialization\n\nThis tutorial illustrates how to use the CompoundDataset to:\n1) Select a few subjects/sessions/runs in an existing dataset\n2) Merge two CompoundDataset into a new one\n3) ... and finally use this new dataset on a pipeline\n(this steps is not specific to CompoundDataset)\n\nLet's define a paradigm and a pipeline for evaluation first.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "paradigm = P300()\npipelines = {}\npipelines[\"MDM\"] = make_pipeline(ERPCovariances(estimator=\"lwf\"), MDM(metric=\"riemann\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creation a selection of subject\n\nWe are going to great two CompoundDataset, namely CustomDataset1 &  2.\nA CompoundDataset accepts a subjects_list of subjects.\nIt is a list of tuple. A tuple contains 4 values:\n- the original dataset\n- the subject number to select\n- the sessions. It can be:\n  - a session name ('session_0')\n  - a list of sessions (['session_0', 'session_1'])\n  - `None` to select all the sessions attributed to a subjet\n- the runs. As for sessions, it can be a single run name, a list or `None`` (to select all runs).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class CustomDataset1(CompoundDataset):\n    def __init__(self):\n        biVR = VirtualReality(virtual_reality=True, screen_display=True)\n        runs = blocks_reps([1, 3], [1, 2, 3, 4, 5])\n        subjects_list = [\n            (biVR, 1, \"VR\", runs),\n            (biVR, 2, \"VR\", runs),\n        ]\n        CompoundDataset.__init__(\n            self,\n            subjects_list=subjects_list,\n            events=dict(Target=2, NonTarget=1),\n            code=\"D1\",\n            interval=[0, 1.0],\n            paradigm=\"p300\",\n        )\n\n\nclass CustomDataset2(CompoundDataset):\n    def __init__(self):\n        bi2014 = bi2014a()\n        subjects_list = [\n            (bi2014, 4, None, None),\n            (bi2014, 7, None, None),\n        ]\n        CompoundDataset.__init__(\n            self,\n            subjects_list=subjects_list,\n            events=dict(Target=2, NonTarget=1),\n            code=\"D2\",\n            interval=[0, 1.0],\n            paradigm=\"p300\",\n        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Merging the datasets\n\nWe are now going to merge the two CompoundDataset into a single one.\nThe implementation is straigh forward. Instead of providing a list of subjects,\nyou should provide a list of CompoundDataset.\nsubjects_list = [CustomDataset1(), CustomDataset2()]\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class CustomDataset3(CompoundDataset):\n    def __init__(self):\n        subjects_list = [CustomDataset1(), CustomDataset2()]\n        CompoundDataset.__init__(\n            self,\n            subjects_list=subjects_list,\n            events=dict(Target=2, NonTarget=1),\n            code=\"D3\",\n            interval=[0, 1.0],\n            paradigm=\"p300\",\n        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate and display\n\nLet's use a WithinSessionEvaluation to evaluate our new dataset.\nIf you already new how to do this, nothing changed:\nThe CompoundDataset can be used as a `normal` dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datasets = [CustomDataset3()]\nevaluation = WithinSessionEvaluation(\n    paradigm=paradigm, datasets=datasets, overwrite=False, suffix=\"newdataset\"\n)\nscores = evaluation.process(pipelines)\n\nprint(scores)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}