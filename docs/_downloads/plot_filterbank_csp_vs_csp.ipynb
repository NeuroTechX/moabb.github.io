{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# FilterBank CSP versus CSP\n\n\nThis Example show a comparison of CSP versus FilterBank CSP on the\nvery popular dataset 2a from the BCI competition IV.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Alexandre Barachant <alexandre.barachant@gmail.com>\n#\n# License: BSD (3-clause)\n\nimport moabb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.pipeline import make_pipeline\n\nfrom mne.decoding import CSP\n\nfrom moabb.datasets import BNCI2014001\nfrom moabb.paradigms import LeftRightImagery, FilterBankLeftRightImagery\nfrom moabb.evaluations import CrossSessionEvaluation\nfrom moabb.pipelines.utils import FilterBank\n\nmoabb.set_log_level('info')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create pipelines\n----------------\n\nThe CSP implementation from MNE is used. We selected 8 CSP components, as\nusually done in the litterature.\n\nThe second pipeline is the filter bank CSP. We use the FilterBank object\nwith a CSP estimator. We set up the CSP to 4 components, to compensate for\nthe higher dimensionality.\n\nThe two pipelines will be applied on two different paradigm, so they have\ntheir own dict.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipelines = {}\npipelines['CSP + LDA'] = make_pipeline(CSP(n_components=8),\n                                       LDA())\n\npipelines_fb = {}\npipelines_fb['FBCSP + LDA'] = make_pipeline(FilterBank(CSP(n_components=4)),\n                                            LDA())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluation\n----------\n\nSince two different preprocessing will be applied, we have two different\nparadigm objects. We have to make sure their filter matchs so the comparison\nwill be fair.\n\nThe first one is a standard `LeftRightImagery` with a 8 to 35 Hz broadband\nfilter.\n\nThe second is a `FilterBankLeftRightImagery` with a bank of 6 filter, ranging\nfrom 8 to 35 Hz.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datasets = [BNCI2014001()]\noverwrite = False  # set to True if we want to overwrite cached results\n\n# broadband filters\nfmin=8\nfmax=35\nparadigm = LeftRightImagery(fmin=fmin, fmax=fmax)\nevaluation = CrossSessionEvaluation(paradigm=paradigm, datasets=datasets,\n                                    suffix='examples', overwrite=overwrite)\nresults = evaluation.process(pipelines)\n\n# cashed results might return other pipelines\nresults = results[results.pipeline == 'CSP + LDA']\n\n# bank of 6 filter, by 4 Hz increment\nfilters = [[8, 12], [12, 16], [16, 20], [20, 24], [24, 28], [28, 35]]\nparadigm = FilterBankLeftRightImagery(filters=filters)\nevaluation = CrossSessionEvaluation(paradigm=paradigm, datasets=datasets,\n                                    suffix='examples', overwrite=overwrite)\nresults_fb = evaluation.process(pipelines_fb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After processing the two, we simply concatenate the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results = pd.concat([results, results_fb])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot Results\n----------------\n\nHere we plot the results. We the first plot is a pointplot with the average\nperformance of each pipeline across session and subjects.\nThe second plot is a paired scatter plot. Each point representing the score\nof a single session. An algorithm will outperforms another is most of the\npoints are in its quadrant.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=[8, 4], sharey=True)\n\nsns.stripplot(data=results, y='score', x='pipeline', ax=axes[0], jitter=True,\n              alpha=.5, zorder=1, palette=\"Set1\")\nsns.pointplot(data=results, y='score', x='pipeline', ax=axes[0],\n              zorder=1, palette=\"Set1\")\n\naxes[0].set_ylabel('ROC AUC')\naxes[0].set_ylim(0.5, 1)\n\n# paired plot\npaired = results.pivot_table(values='score', columns='pipeline',\n                             index=['subject', 'session'])\npaired = paired.reset_index()\n\nsns.regplot(data=paired, y='FBCSP + LDA', x='CSP + LDA', ax=axes[1],\n            fit_reg=False)\naxes[1].plot([0, 1], [0, 1], ls='--', c='k')\naxes[1].set_xlim(0.5, 1)\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}