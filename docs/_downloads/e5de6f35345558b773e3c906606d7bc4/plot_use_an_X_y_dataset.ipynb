{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Tutorial 6: Using X y data (epoched data) instead of continuous signal\nSometimes, we have data in the format of X and y, rather than as a continuous\nsignal. In such cases, the data is already segmented into epochs. This creates\na problem, because MOABB is designed to work with continuous data organized by\nsubjects and sessions.\n\nThe following tutorial creates a dataset that contains data in the form of\nepochs. A special paradigm is provided, which calls an additional method on\nthe dataset so that MOABB can process it correctly. After this, a standard\nclassification is performed.\n\nThe dataset provides the X y data as a single user and a single session.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Anton ANDREEV\n\nimport numpy as np\nimport pandas as pd\nfrom pyriemann.estimation import XdawnCovariances\nfrom pyriemann.tangentspace import TangentSpace\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, make_scorer\nfrom sklearn.pipeline import make_pipeline\n\nfrom moabb.datasets.base import BaseDataset\nfrom moabb.evaluations import (\n    WithinSessionEvaluation,\n)\nfrom moabb.paradigms.base import BaseParadigm\n\n\nclass RawEpochParadigm(BaseParadigm):\n    \"\"\"\n    A minimal paradigm that directly uses dataset.get_epoch_data()\n    with no filtering, epoching, or signal processing.\n\n    Useful when your data is in the format X, y.\n    \"\"\"\n\n    def __init__(self):\n        # filters=None indicates no filtering is done\n        super().__init__(filters=[])\n        self.return_epochs = False\n\n    def get_data(self, dataset, subjects, return_epochs=False, **kwargs):\n        X_all, y_all, meta_all = [], [], []\n\n        for subject in subjects:\n            X, y = dataset.get_epoch_data(\n                subject\n            )  # (n_trials, n_channels, n_times), (n_trials,)\n\n            if isinstance(y, pd.Series):\n                y = y.values\n\n            n_trials = len(y)\n            X_all.append(X)\n            y_all.append(y)\n\n            # Build metadata for each trial, filling defaults for session and run\n            meta = pd.DataFrame(\n                {\n                    \"subject\": [subject] * n_trials,\n                    \"session\": [1] * n_trials,  # Default to 1 if sessions unknown\n                    \"run\": [1] * n_trials,  # Default to 1 if runs unknown\n                    \"trial\": list(range(n_trials)),\n                    \"label\": y,\n                }\n            )\n\n            meta_all.append(meta)\n\n        X = np.concatenate(X_all, axis=0)\n        y = np.concatenate(y_all, axis=0)\n        meta = pd.concat(meta_all, ignore_index=True)\n\n        return X, y, meta\n\n    def is_valid(self, dataset):\n        return hasattr(dataset, \"get_epoch_data\")\n\n    @property\n    def scoring(self):\n        return make_scorer(accuracy_score)\n\n    def used_events(self, dataset):\n        # Return event dict if needed, or {} if irrelevant\n        return {}\n\n    @property\n    def datasets(self):\n        return []\n\n    def make_process_pipelines(self, dataset, **kwargs):\n        # Return a dummy no-op processing pipeline\n        return [lambda raw: raw]\n\n\nclass DummyRawEpochsDataset(BaseDataset):\n    \"\"\"\n    Minimal custom dataset compatible with RawEpochParadigm.\n    \"\"\"\n\n    def __init__(self, subjects=[1]):\n        super().__init__(\n            subjects=subjects,\n            sessions_per_subject=1,\n            events={\"left\": 0, \"right\": 1},  # required dummy event map\n            code=\"DummyRawEpochsDataset\",\n            interval=[0, 1],\n            paradigm=\"RawEpochParadigm\",\n        )\n        self.n_channels = 8\n        self.n_times = 128\n        self.n_trials = 100  # number of epochs\n        self.n_classes = 2\n\n    def data_path(\n        self, subject, path=None, force_update=False, update_path=True, verbose=None\n    ):\n        return None  # Not needed since we generate synthetic data\n\n    def _get_single_subject_data(self, subject):\n        raise NotImplementedError(\"Not used with RawEpochParadigm\")\n\n    def get_epoch_data(self, subject=None):\n        \"\"\"\n        Simulates epochs: shape (trials, channels, time), and labels\n        Trials is the number of epochs to generate.\n        \"\"\"\n        rng = np.random.default_rng(seed=subject)\n        X = rng.standard_normal((self.n_trials, self.n_channels, self.n_times))\n        y = rng.integers(low=0, high=self.n_classes, size=self.n_trials)\n        return X, y\n\n\ndataset = DummyRawEpochsDataset()\n\nparadigm = RawEpochParadigm()  # using the new special RawEpochParadigm paradigm\n\nX, labels, meta = paradigm.get_data(dataset=dataset, subjects=[1])\n\nprint(\"Epochs count before classification\", len(labels))\n\nevaluation = WithinSessionEvaluation(\n    paradigm=paradigm, datasets=dataset, overwrite=True, suffix=\"motan\"\n)\n\npipelines = {}\n\npipelines[\"XD+TS+LR\"] = make_pipeline(\n    XdawnCovariances(nfilter=4, estimator=\"oas\", xdawn_estimator=\"scm\"),\n    TangentSpace(),\n    LogisticRegression(),\n)\n\nprint(\"Start classification ...\")\nscores = evaluation.process(pipelines)\n\nprint(\"\\n\\nResults:\\n\", scores[[\"score\", \"time\", \"samples\", \"dataset\", \"pipeline\"]])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}