{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Tutorial: Within-Session Splitting on Real MI Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Thomas, Kooiman, Radovan Vodila, Jorge Sanmartin Martinez, and Paul Verhoeven\n#\n# License: BSD (3-clause)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The justification and goal for within-session splitting\nIn short, because we want to prevent the model from recognizing the subject\nand learning subject-specific representations instead of focusing on the task at hand.\n\nIn brain-computer interface (BCI) research, careful data splitting is critical.\nA naive train_test_split can easily lead to misleading results, especially in small EEG datasets,\nwhere models may accidentally learn to recognize subjects instead of decoding the actual brain task.\nEach brain produces unique signals, and unless we're careful, the model can exploit these as shortcuts \u2014\nleading to artificially high test accuracy that doesn\u2019t generalize in practice.\n\nTo avoid this, we use within-session splitting, where training and testing are done\non different trials from the same session. This ensures the model is evaluated under commonly used,\nconsistent conditions while still preventing overfitting to trial-specific noise.\n\nThis approach forms a critical foundation in the MOABB evaluation framework,\nwhich supports three levels of model generalization:\n\n- Within-session: test generalization across trials within a single session\n- Cross-session: test generalization across different recording sessions\n- Cross-subject: test generalization across different brains\n\nWhere Within-session and cross-session are generalized across the same subject, cross-subject is generalized between (groups of) subjects.\n\nEach level decreases in specialization, moving from highly subject-specific models,\nto those that can generalize across individuals.\n\nThis tutorial focuses on within-session evaluation to establish a reliable\nbaseline for model performance before attempting more challenging generalization tasks.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing the necessary libraries\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\n\nimport matplotlib.pyplot as plt\n\n# Standard imports\nimport pandas as pd\nimport seaborn as sns\n\n# MNE + sklearn for pipeline\nfrom mne.decoding import CSP\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.pipeline import make_pipeline\n\nimport moabb\n\n# MOABB components\nfrom moabb.datasets import BNCI2014_001\nfrom moabb.evaluations.splitters import WithinSessionSplitter\nfrom moabb.paradigms import LeftRightImagery\n\n\n# Suppress warnings and enable informative logging\nwarnings.filterwarnings(\"ignore\")\nmoabb.set_log_level(\"info\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the dataset\nIn this example we use 3 subjects of the :class:`moabb.datasets.BNCI2014_001` dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = BNCI2014_001()\ndataset.subject_list = [1, 2, 3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract data: epochs (X), labels (y), and trial metadata (meta)\nFor this dataset we use the :class:`moabb.paradigms.LeftRightImagery` paradigm.\nAdditionally, we use the `get_data` method to download, preprocess, epoch, and label the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "paradigm = LeftRightImagery()\n# This call downloads (if needed), preprocesses, epochs, and labels the data\nX, y, meta = paradigm.get_data(dataset=dataset, subjects=dataset.subject_list)\n\n# Inspect the shapes: X is trials \u00d7 channels \u00d7 timepoints; y is labels; meta is info\nprint(\"X shape (trials, channels, timepoints):\", X.shape)\nprint(\"y shape (trials,):\", y.shape)\nprint(\"meta shape (trials, info columns):\", meta.shape)\nprint(meta.head())  # shows subject/session for each trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualising a single epoch.\nPlot a single epoch (e.g., the first trial), to see what's in this dataset. (limiting to 3 channels for simplicity sake).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))\nplt.plot(X[0][0:3].T)  # Transpose to plot channels over time\nplt.title(\"Epoch 0: EEG Channels Over Time\")\nplt.xlabel(\"Timepoints\")\nplt.ylabel(\"Amplitude\")\nplt.legend([f\"Channel {i + 1}\" for i in range(3)], loc=\"upper right\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build a classification pipeline: CSP to LDA\nWe use Common Spatial Patterns (CSP) finds spatial filters that maximize variance difference between classes.\nAnd then use Linear Discriminant Analysis (LDA) as a simple linear classifier on the extracted CSP features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipe = make_pipeline(\n    CSP(n_components=6, reg=None),  # reduce to 6 CSP components\n    LDA(),  # classify based on these features\n)\npipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instantiate WithinSessionSplitter\nWe want 5-fold cross-validation (CV) within each subject \u00d7 session grouping\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "wss = WithinSessionSplitter(n_folds=5, shuffle=True, random_state=404)\nprint(f\"Splitter config: folds={wss.n_folds}, shuffle={wss.shuffle}\")\n\n# How many total splits? equals n_folds \u00d7 (num_subjects \u00d7 sessions per subject)\ntotal_folds = wss.get_n_splits(meta)\nprint(\"Total folds (num_subjects \u00d7 sessions \u00d7 n_folds):\", total_folds)\n# If wss is applied to a dataset where a subject has only one session,\n# the splitter will skip that subject silently. Therefore, we raise an error.\nif wss.get_n_splits(meta) == 0:\n    raise RuntimeError(\"No splits generated: check that each subject has \u22652 sessions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Manual evaluation loop: train/test each fold\nWe'll collect one row per fold: which subject/session was held out and its score\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "records = []\nfor fold_id, (train_idx, test_idx) in enumerate(wss.split(y, meta)):\n    # Slice our epoch array and labels\n    X_train, X_test = X[train_idx], X[test_idx]\n    y_train, y_test = y[train_idx], y[test_idx]\n\n    # Fit the CSP+LDA pipeline on the training fold\n    pipe.fit(X_train, y_train)\n    # Evaluate on the held-out trials\n    score = pipe.score(X_test, y_test)\n\n    # Identify which subject & session these test trials come from\n    # (all test_idx in one fold share the same subject/session)\n    subject_held = meta.iloc[test_idx][\"subject\"].iat[0]\n    session_held = meta.iloc[test_idx][\"session\"].iat[0]\n\n    # Record information for later analysis\n    records.append(\n        {\n            \"fold\": fold_id,\n            \"subject\": subject_held,\n            \"session\": session_held,\n            \"score\": score,\n        }\n    )\n\n# Create a DataFrame of fold results\ndf = pd.DataFrame(records)\n\n# Add a new column to indicate whether the data is train or test\ndf[\"split\"] = df[\"session\"].apply(lambda x: \"test\" if \"test\" in x else \"train\")\n\n# Show the first few rows: one entry per fold\nprint(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of results\nWe can quickly see per-subject, per-session performance:\nWe see subject 2\u2019s Session 1 has lower mean accuracy, suggesting session variability.\nNote: you could plot these numbers to visually compare sessions,\nbut here we print them to focus on the splitting logic itself.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "summary = df.groupby([\"subject\", \"session\"])[\"score\"].agg([\"mean\", \"std\"]).reset_index()\nprint(\"\\nSummary of within-session fold scores (mean \u00b1 std):\")\nprint(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualisation of the results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df[\"subject\"] = df[\"subject\"].astype(str)\nplt.figure(figsize=(8, 6))\nsns.barplot(x=\"score\", y=\"subject\", hue=\"session\", data=df, orient=\"h\", palette=\"viridis\")\nplt.xlabel(\"Classification accuracy\")\nplt.ylabel(\"Subject\")\nplt.title(\"Within-session CSP+LDA performance\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualisation of the data split\nFor our 3 subjects, we see that each subject has 5 folds of training data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_subject_split(ax, df):\n    \"\"\"Create a bar plot showing the split of subject data into train and test.\"\"\"\n    colors = [\"#3A6190\", \"#DDF2FF\"]  # Colors for train and test\n\n    # Count the number of train and test samples for each subject\n    subject_counts = df.groupby([\"subject\", \"split\"]).size().unstack(fill_value=0)\n\n    # Plot the train and test counts for each subject\n    subject_counts.plot(\n        kind=\"barh\",\n        stacked=True,\n        color=colors,\n        ax=ax,\n        width=0.7,\n    )\n\n    ax.set(\n        xlabel=\"Number of samples\",\n        ylabel=\"Subject\",\n        title=\"Train-Test Split by Subject\",\n    )\n    ax.legend([\"Train\", \"Test\"], loc=\"lower right\")\n    ax.invert_yaxis()\n    return ax\n\n\n# Create a new figure for the subject split plot\nfig, ax = plt.subplots(figsize=(8, 6))\n# Add the subject split plot to the figure\nplot_subject_split(ax, df)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}