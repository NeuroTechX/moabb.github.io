{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Statistical Analysis\n\n\nThe MOABB codebase comes with convenience plotting utilities and some\nstatistical testing. This tutorial focuses on what those exactly are and how\nthey can be used.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Vinay Jayaram <vinayjayaram13@gmail.com>\n#\n# License: BSD (3-clause)\n\nimport moabb\nimport matplotlib.pyplot as plt\nimport moabb.analysis.plotting as moabb_plt\nfrom moabb.analysis.meta_analysis import find_significant_differences, compute_dataset_statistics  # flake8: noqa\n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\n\nfrom mne.decoding import CSP\n\nfrom pyriemann.estimation import Covariances\nfrom pyriemann.tangentspace import TangentSpace\n\nfrom moabb.datasets import BNCI2014001\nfrom moabb.paradigms import LeftRightImagery\nfrom moabb.evaluations import CrossSessionEvaluation\n\nmoabb.set_log_level('info')\n\nprint(__doc__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results Generation\n---------------------\n\nFirst we need to set up a paradigm, dataset list, and some pipelines to\ntest. This is explored more in the examples -- we choose a left vs right\nimagery paradigm with a single bandpass. There is only one dataset here but\nany number can be added without changing this workflow.\n\nCreate pipelines\n----------------\n\nPipelines must be a dict of sklearn pipeline transformer.\n\nThe csp implementation from MNE is used. We selected 8 CSP components, as\nusually done in the litterature.\n\nThe riemannian geometry pipeline consists in covariance estimation, tangent\nspace mapping and finaly a logistic regression for the classification.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipelines = {}\n\npipelines['CSP + LDA'] = make_pipeline(CSP(n_components=8),\n                                       LDA())\n\npipelines['RG + LR'] = make_pipeline(Covariances(),\n                                     TangentSpace(),\n                                     LogisticRegression())\n\npipelines['CSP + LR'] = make_pipeline(CSP(n_components=8),\n                                      LogisticRegression())\n\npipelines['RG + LDA'] = make_pipeline(Covariances(),\n                                      TangentSpace(),\n                                      LDA())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluation\n----------\n\nWe define the paradigm (LeftRightImagery) and the dataset (BNCI2014001).\nThe evaluation will return a dataframe containing a single AUC score for\neach subject / session of the dataset, and for each pipeline.\n\nResults are saved into the database, so that if you add a new pipeline, it\nwill not run again the evaluation unless a parameter has changed. Results can\nbe overwritten if necessary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "paradigm = LeftRightImagery()\ndatasets = [BNCI2014001()]\noverwrite = False  # set to True if we want to overwrite cached results\nevaluation = CrossSessionEvaluation(paradigm=paradigm, datasets=datasets,\n                                    suffix='examples', overwrite=overwrite)\n\nresults = evaluation.process(pipelines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MOABB plotting\n----------------\n\nHere we plot the results using some of the convenience methods within the\ntoolkit.  The score_plot visualizes all the data with one score per subject\nfor every dataset and pipeline.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = moabb_plt.score_plot(results)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For a comparison of two algorithms, there is the paired_plot, which plots\nperformance in one versus the performance in the other over all chosen\ndatasets. Note that there is only one score per subject, regardless of the\nnumber of sessions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = moabb_plt.paired_plot(results, 'CSP + LDA', 'RG + LDA')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Statistical testing and further plots\n----------------------------------------\n\nIf the statistical significance of results is of interest, the method\ncompute_dataset_statistics allows one to show a meta-analysis style plot as\nwell. For an overview of how all algorithms perform in comparison with each\nother, the method find_significant_differences and the summary_plot are\npossible.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stats = compute_dataset_statistics(results)\nP, T = find_significant_differences(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The meta-analysis style plot shows the standardized mean difference within\neach tested dataset for the two algorithms in question, in addition to a\nmeta-effect and significances both per-dataset and overall.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = moabb_plt.meta_analysis_plot(stats, 'CSP + LDA', 'RG + LDA')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The summary plot shows the effect and significance related to the hypothesis\nthat the algorithm on the y-axis significantly out-performed the algorithm on\nthe x-axis over all datasets\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "moabb_plt.summary_plot(P, T)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}