
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_tutorials/tutorial_1_simple_example_motor_imagery.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_tutorials_tutorial_1_simple_example_motor_imagery.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorials_tutorial_1_simple_example_motor_imagery.py:


================================
Tutorial 1: Simple Motor Imagery
================================

In this example, we will go through all the steps to make a simple BCI
classification task, downloading a dataset and using a standard classifier. We
choose the dataset 2a from BCI Competition IV, a motor imagery task. We will
use a CSP to enhance the signal-to-noise ratio of the EEG epochs and a LDA to
classify these signals.

.. GENERATED FROM PYTHON SOURCE LINES 12-34

.. code-block:: default

    # Authors: Pedro L. C. Rodrigues, Sylvain Chevallier
    #
    # https://github.com/plcrodrigues/Workshop-MOABB-BCI-Graz-2019

    import warnings

    import matplotlib.pyplot as plt
    import pandas as pd
    import seaborn as sns
    from mne.decoding import CSP
    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
    from sklearn.pipeline import make_pipeline

    import moabb
    from moabb.datasets import BNCI2014001
    from moabb.evaluations import WithinSessionEvaluation
    from moabb.paradigms import LeftRightImagery


    moabb.set_log_level("info")
    warnings.filterwarnings("ignore")








.. GENERATED FROM PYTHON SOURCE LINES 35-48

Instantiating Dataset
---------------------

The first thing to do is to instantiate the dataset that we want to analyze.
MOABB has a list of many different datasets, each one containing all the
necessary information for describing them, such as the number of subjects,
size of trials, names of classes, etc.

The dataset class has methods for:

- downloading its files from some online source (e.g. Zenodo)
- importing the data from the files in whatever extension they might be
  (like .mat, .gdf, etc.) and instantiate a Raw object from the MNE package

.. GENERATED FROM PYTHON SOURCE LINES 48-52

.. code-block:: default


    dataset = BNCI2014001()
    dataset.subject_list = [1, 2, 3]








.. GENERATED FROM PYTHON SOURCE LINES 53-58

Accessing EEG Recording
-----------------------

As an example, we may access the EEG recording from a given session and a
given run as follows:

.. GENERATED FROM PYTHON SOURCE LINES 58-61

.. code-block:: default


    sessions = dataset.get_data(subjects=[1])








.. GENERATED FROM PYTHON SOURCE LINES 62-66

This returns a MNE Raw object that can be manipulated. This might be enough
for some users, since the pre-processing and epoching steps can be easily
done via MNE. However, to conduct an assessment of several classifiers on
multiple subjects, MOABB ends up being a more appropriate option.

.. GENERATED FROM PYTHON SOURCE LINES 66-73

.. code-block:: default


    subject = 1
    session_name = "session_T"
    run_name = "run_1"
    raw = sessions[subject][session_name][run_name]









.. GENERATED FROM PYTHON SOURCE LINES 74-82

Choosing a Paradigm
-------------------

Once we have instantiated a dataset, we have to choose a paradigm. This
object is responsible for filtering the data, epoching it, and extracting
the labels for each epoch. Note that each dataset comes with the names of
the paradigms to which it might be associated. It would not make sense to
process a P300 dataset with a MI paradigm object.

.. GENERATED FROM PYTHON SOURCE LINES 82-85

.. code-block:: default


    print(dataset.paradigm)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    imagery




.. GENERATED FROM PYTHON SOURCE LINES 86-89

For the example below, we will consider the paradigm associated to
left-hand/right-hand motor imagery task, but there are other options in
MOABB for motor imagery, P300 or SSVEP.

.. GENERATED FROM PYTHON SOURCE LINES 89-92

.. code-block:: default


    paradigm = LeftRightImagery()








.. GENERATED FROM PYTHON SOURCE LINES 93-95

We may check the list of all datasets available in MOABB for using with this
paradigm (note that BNCI2014001 is in it)

.. GENERATED FROM PYTHON SOURCE LINES 95-98

.. code-block:: default


    print(paradigm.datasets)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [<moabb.datasets.bnci.BNCI2014001 object at 0x7fd83166a3a0>, <moabb.datasets.bnci.BNCI2014004 object at 0x7fd83166ac10>, <moabb.datasets.gigadb.Cho2017 object at 0x7fd83166a6a0>, <moabb.datasets.Lee2019.Lee2019_MI object at 0x7fd83166a700>, <moabb.datasets.mpi_mi.MunichMI object at 0x7fd83166a2b0>, <moabb.datasets.physionet_mi.PhysionetMI object at 0x7fd83166a8b0>, <moabb.datasets.schirrmeister2017.Schirrmeister2017 object at 0x7fd83166afa0>, <moabb.datasets.bbci_eeg_fnirs.Shin2017A object at 0x7fd83166a0d0>, <moabb.datasets.Weibo2014.Weibo2014 object at 0x7fd83166ae20>, <moabb.datasets.Zhou2016.Zhou2016 object at 0x7fd83166a490>]




.. GENERATED FROM PYTHON SOURCE LINES 99-103

The data from a list of subjects could be preprocessed and return as a 3D
numpy array `X`, follow a scikit-like format with the associated `labels`.
The `meta` object contains all information regarding the subject, the
session and the run associated to each trial.

.. GENERATED FROM PYTHON SOURCE LINES 103-105

.. code-block:: default

    X, labels, meta = paradigm.get_data(dataset=dataset, subjects=[1])








.. GENERATED FROM PYTHON SOURCE LINES 106-114

Create Pipeline
---------------

Our goal is to evaluate the performance of a given classification pipeline
(or several of them) when it is applied to the epochs from the previously
chosen dataset. We will consider a very simple classification pipeline in
which the dimension of the epochs are reduced via a CSP step and then
classified via a linear discriminant analysis.

.. GENERATED FROM PYTHON SOURCE LINES 114-117

.. code-block:: default


    pipeline = make_pipeline(CSP(n_components=8), LDA())








.. GENERATED FROM PYTHON SOURCE LINES 118-132

Evaluation
----------

To evaluate the score of this pipeline, we use the `evaluation` class. When
instantiating it, we say which paradigm we want to consider, a list with the
datasets to analyze, and whether the scores should be recalculated each time
we run the evaluation or if MOABB should create a cache file.

Note that there are different ways of evaluating a classifier; in this
example, we choose `WithinSessionEvaluation`, which consists of doing a
cross-validation procedure where the training and testing partitions are from
the same recording session of the dataset. We could have used
`CrossSessionEvaluation`, which takes all but one session as training
partition and the remaining one as testing partition.

.. GENERATED FROM PYTHON SOURCE LINES 132-140

.. code-block:: default


    evaluation = WithinSessionEvaluation(
        paradigm=paradigm,
        datasets=[dataset],
        overwrite=True,
        hdf5_path=None,
    )








.. GENERATED FROM PYTHON SOURCE LINES 141-142

We obtain the results in the form of a pandas dataframe

.. GENERATED FROM PYTHON SOURCE LINES 142-145

.. code-block:: default


    results = evaluation.process({"csp+lda": pipeline})





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    001-2014-WithinSession:   0%|          | 0/3 [00:00<?, ?it/s]    001-2014-WithinSession:  33%|###3      | 1/3 [00:05<00:10,  5.44s/it]    001-2014-WithinSession:  67%|######6   | 2/3 [00:10<00:05,  5.40s/it]    001-2014-WithinSession: 100%|##########| 3/3 [00:16<00:00,  5.40s/it]    001-2014-WithinSession: 100%|##########| 3/3 [00:16<00:00,  5.40s/it]




.. GENERATED FROM PYTHON SOURCE LINES 146-149

The results are stored in locally, to avoid recomputing the results each time.
It is saved in `hdf5_path` if defined or in ~/mne_data/results  otherwise.
To export the results in CSV:

.. GENERATED FROM PYTHON SOURCE LINES 149-152

.. code-block:: default


    results.to_csv("./results_part2-1.csv")








.. GENERATED FROM PYTHON SOURCE LINES 153-154

To load previously obtained results saved in CSV

.. GENERATED FROM PYTHON SOURCE LINES 154-157

.. code-block:: default


    results = pd.read_csv("./results_part2-1.csv")








.. GENERATED FROM PYTHON SOURCE LINES 158-165

Plotting Results
----------------

We create a figure with the seaborn package comparing the classification
score for each subject on each session. Note that the 'subject' field from
the `results` is given in terms of integers, but seaborn accepts only
strings for its labeling. This is why we create the field 'subj'.

.. GENERATED FROM PYTHON SOURCE LINES 165-172

.. code-block:: default


    fig, ax = plt.subplots(figsize=(8, 7))
    results["subj"] = results["subject"].apply(str)
    sns.barplot(
        x="score", y="subj", hue="session", data=results, orient="h", palette="viridis", ax=ax
    )
    plt.show()



.. image-sg:: /auto_tutorials/images/sphx_glr_tutorial_1_simple_example_motor_imagery_001.png
   :alt: tutorial 1 simple example motor imagery
   :srcset: /auto_tutorials/images/sphx_glr_tutorial_1_simple_example_motor_imagery_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  21.725 seconds)


.. _sphx_glr_download_auto_tutorials_tutorial_1_simple_example_motor_imagery.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: tutorial_1_simple_example_motor_imagery.py <tutorial_1_simple_example_motor_imagery.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: tutorial_1_simple_example_motor_imagery.ipynb <tutorial_1_simple_example_motor_imagery.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
