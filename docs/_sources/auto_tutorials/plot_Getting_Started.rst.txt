.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_auto_tutorials_plot_Getting_Started.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorials_plot_Getting_Started.py:

=========================
Getting Started
=========================

This tutorial takes you through a basic working example of how to use this
codebase, including all the different components, up to the results
generation. If you'd like to know about the statistics and plotting, see the
next tutorial.




.. code-block:: python

    # Authors: Vinay Jayaram <vinayjayaram13@gmail.com>
    #
    # License: BSD (3-clause)








Introduction
--------------------
To use the codebase you need an evaluation and a paradigm, some algorithms,
and a list of datasets to run it all on. You can find those in the following
submodules; detailed tutorials are given for each of them.



.. code-block:: python


    from moabb.datasets import BNCI2014001
    from moabb.paradigms import LeftRightImagery
    from moabb.evaluations import CrossSessionEvaluation
    from moabb.datasets import utils







In order to create pipelines within a script, you will likely need at least
the make_pipeline function. They can also be specified via a .yml file. Here
we will make a couple pipelines just for convenience



.. code-block:: python


    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
    from sklearn.pipeline import make_pipeline
    from sklearn.svm import SVC
    from sklearn.model_selection import GridSearchCV
    from moabb.pipelines.features import LogVariance
    import numpy as np







If you would like to specify the logging level when it is running, you can
use the standard python logging commands through the top-level moabb module



.. code-block:: python

    import moabb
    moabb.set_log_level('info')







Create pipelines
----------------

We create two pipelines: channel-wise log variance followed by LDA, and
channel-wise log variance followed by a cross-validated SVM (note that a
cross-validation via scikit-learn cannot be described in a .yml file). For
later in the process, the pipelines need to be in a dictionary where the key
is the name of the pipeline and the value is the Pipeline object



.. code-block:: python


    pipelines = {}
    pipelines['AM + LDA'] = make_pipeline(LogVariance(),
                                          LDA())
    parameters = {'C': np.logspace(-2, 2, 10)}
    clf = GridSearchCV(SVC(kernel='linear'), parameters)
    pipe = make_pipeline(LogVariance(), clf)

    pipelines['AM + SVM'] = pipe







Datasets
-----------------

Datasets can be specified in many ways: Each paradigm has a property
'datasets' which returns the datasets that are appropriate for that paradigm



.. code-block:: python


    print(LeftRightImagery().datasets)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [<moabb.datasets.bnci.BNCI2014001 object at 0x7f74fc5b1cc0>, <moabb.datasets.bnci.BNCI2014004 object at 0x7f74fc5b1630>, <moabb.datasets.gigadb.Cho2017 object at 0x7f74fc5b1278>, <moabb.datasets.mpi_mi.MunichMI object at 0x7f74fc5b13c8>, <moabb.datasets.physionet_mi.PhysionetMI object at 0x7f74fc5b16d8>, <moabb.datasets.schirrmeister2017.Schirrmeister2017 object at 0x7f74fc5b1eb8>, <moabb.datasets.bbci_eeg_fnirs.Shin2017A object at 0x7f74fc7222e8>, <moabb.datasets.Weibo2014.Weibo2014 object at 0x7f74fc5b1860>, <moabb.datasets.Zhou2016.Zhou2016 object at 0x7f74fc5b1160>]


Or you can run a search through the available datasets:



.. code-block:: python

    print(utils.dataset_search(paradigm='imagery', total_classes=2))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [<moabb.datasets.alex_mi.AlexMI object at 0x7f74fc5b1630>, <moabb.datasets.bnci.BNCI2014001 object at 0x7f74fc5b13c8>, <moabb.datasets.bnci.BNCI2014002 object at 0x7f74fc5b16d8>, <moabb.datasets.bnci.BNCI2014004 object at 0x7f74fc5b1eb8>, <moabb.datasets.bnci.BNCI2015001 object at 0x7f74fc5b1860>, <moabb.datasets.bnci.BNCI2015004 object at 0x7f74fc5b1710>, <moabb.datasets.gigadb.Cho2017 object at 0x7f74fc5b1160>, <moabb.datasets.mpi_mi.MunichMI object at 0x7f74fc5b17f0>, <moabb.datasets.upper_limb.Ofner2017 object at 0x7f74fc5b15f8>, <moabb.datasets.physionet_mi.PhysionetMI object at 0x7f74fc5b1898>, <moabb.datasets.schirrmeister2017.Schirrmeister2017 object at 0x7f74fe0421d0>, <moabb.datasets.bbci_eeg_fnirs.Shin2017A object at 0x7f74fcacef28>, <moabb.datasets.Weibo2014.Weibo2014 object at 0x7f750174fba8>, <moabb.datasets.Zhou2016.Zhou2016 object at 0x7f74fc553ef0>]


Or you can simply make your own list (which we do here due to computational
constraints)



.. code-block:: python


    datasets = [BNCI2014001()]







Paradigm
--------------------

Paradigms define the events, epoch time, bandpass, and other preprocessing
parameters. They have defaults that you can read in the documentation, or you
can simply set them as we do here. A single paradigm defines a method for
going from continuous data to trial data of a fixed size. To learn more look
at the tutorial Exploring Paradigms



.. code-block:: python


    fmin = 8
    fmax = 35
    paradigm = LeftRightImagery(fmin=fmin, fmax=fmax)







Evaluation
--------------------

An evaluation defines how the training and test sets are chosen. This could
be cross-validated within a single recording, or across days, or sessions, or
subjects. This also is the correct place to specify multiple threads.



.. code-block:: python


    evaluation = CrossSessionEvaluation(paradigm=paradigm, datasets=datasets,
                                        suffix='examples', overwrite=False)
    results = evaluation.process(pipelines)







Results are returned as a pandas DataFrame, and from here you can do as you
want with them



.. code-block:: python


    print(results.head())




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    score    ...     pipeline
    0  0.801698    ...     AM + LDA
    1  0.786458    ...     AM + LDA
    2  0.498650    ...     AM + LDA
    3  0.576582    ...     AM + LDA
    4  0.945988    ...     AM + LDA

    [5 rows x 9 columns]


**Total running time of the script:** ( 0 minutes  36.445 seconds)


.. _sphx_glr_download_auto_tutorials_plot_Getting_Started.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_Getting_Started.py <plot_Getting_Started.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_Getting_Started.ipynb <plot_Getting_Started.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
