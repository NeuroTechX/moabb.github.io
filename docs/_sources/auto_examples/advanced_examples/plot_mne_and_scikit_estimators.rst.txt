
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/advanced_examples/plot_mne_and_scikit_estimators.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_advanced_examples_plot_mne_and_scikit_estimators.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_advanced_examples_plot_mne_and_scikit_estimators.py:


==========================
MNE Epochs-based pipelines
==========================

This example shows how to use machine learning pipeline based on MNE Epochs
instead of Numpy arrays. This is useful to make the most of the MNE code base
and to embed EEG specific code inside sklearn pipelines.

We will compare different pipelines for P300:
- Logistic regression, based on MNE Epochs
- XDAWN and Logistic Regression (LR), based on MNE Epochs
- XDAWN extended covariance and LR on tangent space, based on Numpy

.. GENERATED FROM PYTHON SOURCE LINES 16-49

.. code-block:: default

    # Authors: Sylvain Chevallier
    #
    # License: BSD (3-clause)
    # sphinx_gallery_thumbnail_number = 2

    import warnings

    import matplotlib.pyplot as plt
    import pandas as pd
    from mne.decoding import Vectorizer
    from mne.preprocessing import Xdawn
    from pyriemann.estimation import XdawnCovariances
    from pyriemann.tangentspace import TangentSpace
    from sklearn.base import BaseEstimator, TransformerMixin
    from sklearn.linear_model import LogisticRegression
    from sklearn.pipeline import make_pipeline
    from sklearn.preprocessing import StandardScaler

    import moabb
    from moabb.analysis.meta_analysis import (  # noqa: E501
        compute_dataset_statistics,
        find_significant_differences,
    )
    from moabb.analysis.plotting import paired_plot, summary_plot
    from moabb.datasets import BNCI2014009
    from moabb.evaluations import CrossSessionEvaluation
    from moabb.paradigms import P300


    warnings.simplefilter(action="ignore", category=FutureWarning)
    warnings.simplefilter(action="ignore", category=RuntimeWarning)
    moabb.set_log_level("info")








.. GENERATED FROM PYTHON SOURCE LINES 50-54

Loading Dataset
---------------

Load 2 subjects of BNCI 2014-009 dataset, with 3 session each

.. GENERATED FROM PYTHON SOURCE LINES 54-60

.. code-block:: default


    dataset = BNCI2014009()
    dataset.subject_list = dataset.subject_list[:3]
    datasets = [dataset]
    paradigm = P300()








.. GENERATED FROM PYTHON SOURCE LINES 61-71

Get Data (optional)
-------------------

To get access to the EEG signals downloaded from the dataset, you could
use ``dataset.get_data([subject_id)`` to obtain the EEG as MNE Epochs, stored
in a dictionary of sessions and runs.
The ``paradigm.get_data(dataset=dataset, subjects=[subject_id])`` allows to
obtain the preprocessed EEG data, the labels and the meta information. By
default, the EEG is return as a Numpy array. With ``return_epochs=True``, MNE
Epochs are returned.

.. GENERATED FROM PYTHON SOURCE LINES 71-79

.. code-block:: default


    subject_list = [1]
    sessions = dataset.get_data(subject_list)
    X, labels, meta = paradigm.get_data(dataset=dataset, subjects=subject_list)
    epochs, labels, meta = paradigm.get_data(
        dataset=dataset, subjects=subject_list, return_epochs=True
    )








.. GENERATED FROM PYTHON SOURCE LINES 80-91

A Simple MNE Pipeline
---------------------

Using ``return_epochs=True`` in the evaluation, it is possible to design a
pipeline based on MNE Epochs input. Let's create a simple one, that
reshape the input data from epochs, rescale the data and uses a logistic
regression to classify the data. We will need to write a basic Transformer
estimator, that complies with
`sklearn convention <https://scikit-learn.org/stable/developers/develop.html>`_.
This transformer will extract the data from an input Epoch, and reshapes into
2D array.

.. GENERATED FROM PYTHON SOURCE LINES 91-107

.. code-block:: default



    class MyVectorizer(BaseEstimator, TransformerMixin):
        def __init__(self):
            pass

        def fit(self, X, y=None):
            arr = X.get_data()
            self.features_shape_ = arr.shape[1:]
            return self

        def transform(self, X, y=None):
            arr = X.get_data()
            return arr.reshape(len(arr), -1)









.. GENERATED FROM PYTHON SOURCE LINES 108-111

We will define a pipeline that is based on this new class, using a scaler
and a logistic regression. This pipeline is evaluated across session using
ROC-AUC metric.

.. GENERATED FROM PYTHON SOURCE LINES 111-126

.. code-block:: default


    mne_ppl = {}
    mne_ppl["MNE LR"] = make_pipeline(
        MyVectorizer(), StandardScaler(), LogisticRegression(penalty="l1", solver="liblinear")
    )

    mne_eval = CrossSessionEvaluation(
        paradigm=paradigm,
        datasets=datasets,
        suffix="examples",
        overwrite=True,
        return_epochs=True,
    )
    mne_res = mne_eval.process(mne_ppl)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    009-2014-CrossSession:   0%|          | 0/3 [00:00<?, ?it/s]    009-2014-CrossSession:  33%|###3      | 1/3 [00:04<00:08,  4.01s/it]    009-2014-CrossSession:  67%|######6   | 2/3 [00:07<00:03,  3.50s/it]
      0%|                                              | 0.00/18.5M [00:00<?, ?B/s]
      0%|                                     | 8.19k/18.5M [00:00<04:37, 66.8kB/s]
      0%|                                      | 24.6k/18.5M [00:00<02:59, 103kB/s]
      0%|                                     | 35.8k/18.5M [00:00<03:10, 97.1kB/s]
      0%|                                     | 46.1k/18.5M [00:00<03:21, 91.9kB/s]
      0%|                                     | 56.3k/18.5M [00:00<03:31, 87.4kB/s]
      0%|▏                                    | 65.5k/18.5M [00:00<03:41, 83.3kB/s]
      0%|▏                                    | 80.9k/18.5M [00:00<03:13, 95.4kB/s]
      1%|▏                                     | 96.3k/18.5M [00:01<02:57, 104kB/s]
      1%|▏                                      | 113k/18.5M [00:01<02:44, 112kB/s]
      1%|▎                                      | 128k/18.5M [00:01<02:39, 115kB/s]
      1%|▎                                      | 144k/18.5M [00:01<02:32, 120kB/s]
      1%|▎                                      | 161k/18.5M [00:01<02:28, 123kB/s]
      1%|▎                                      | 176k/18.5M [00:01<02:28, 123kB/s]
      1%|▍                                      | 201k/18.5M [00:01<02:06, 145kB/s]
      1%|▍                                      | 216k/18.5M [00:01<02:12, 138kB/s]
      1%|▌                                      | 241k/18.5M [00:02<01:57, 155kB/s]
      1%|▌                                      | 264k/18.5M [00:02<01:50, 165kB/s]
      2%|▌                                      | 289k/18.5M [00:02<01:44, 174kB/s]
      2%|▋                                      | 312k/18.5M [00:02<01:42, 178kB/s]
      2%|▋                                      | 337k/18.5M [00:02<01:39, 184kB/s]
      2%|▊                                      | 360k/18.5M [00:02<01:38, 185kB/s]
      2%|▊                                      | 392k/18.5M [00:02<01:37, 186kB/s]
      2%|▉                                      | 424k/18.5M [00:02<01:28, 204kB/s]
      2%|▉                                      | 457k/18.5M [00:03<01:22, 220kB/s]
      3%|█                                      | 488k/18.5M [00:03<01:18, 230kB/s]
      3%|█                                      | 528k/18.5M [00:03<01:10, 255kB/s]
      3%|█▏                                     | 560k/18.5M [00:03<01:10, 255kB/s]
      3%|█▎                                     | 600k/18.5M [00:03<01:05, 273kB/s]
      3%|█▎                                     | 633k/18.5M [00:03<01:06, 270kB/s]
      4%|█▍                                     | 680k/18.5M [00:03<00:59, 301kB/s]
      4%|█▌                                     | 721k/18.5M [00:03<00:57, 309kB/s]
      4%|█▌                                     | 768k/18.5M [00:04<00:54, 329kB/s]
      4%|█▋                                     | 816k/18.5M [00:04<00:51, 345kB/s]
      5%|█▊                                     | 872k/18.5M [00:04<00:46, 376kB/s]
      5%|█▉                                     | 929k/18.5M [00:04<00:44, 398kB/s]
      5%|██                                     | 992k/18.5M [00:04<00:40, 430kB/s]
      6%|██▏                                   | 1.06M/18.5M [00:04<00:37, 472kB/s]
      6%|██▎                                   | 1.14M/18.5M [00:04<00:34, 503kB/s]
      7%|██▍                                   | 1.21M/18.5M [00:04<00:33, 524kB/s]
      7%|██▋                                   | 1.30M/18.5M [00:05<00:29, 577kB/s]
      7%|██▊                                   | 1.38M/18.5M [00:05<00:27, 614kB/s]
      8%|███                                   | 1.48M/18.5M [00:05<00:25, 660kB/s]
      9%|███▏                                  | 1.58M/18.5M [00:05<00:24, 689kB/s]
      9%|███▍                                  | 1.68M/18.5M [00:05<00:23, 732kB/s]
     10%|███▋                                  | 1.79M/18.5M [00:05<00:21, 779kB/s]
     10%|███▉                                  | 1.92M/18.5M [00:05<00:19, 850kB/s]
     11%|████▏                                 | 2.05M/18.5M [00:05<00:18, 901kB/s]
     12%|████▍                                 | 2.18M/18.5M [00:06<00:17, 956kB/s]
     13%|████▋                                | 2.33M/18.5M [00:06<00:15, 1.01MB/s]
     13%|████▉                                | 2.48M/18.5M [00:06<00:14, 1.07MB/s]
     14%|█████▎                               | 2.64M/18.5M [00:06<00:14, 1.13MB/s]
     15%|█████▌                               | 2.81M/18.5M [00:06<00:13, 1.19MB/s]
     16%|█████▉                               | 2.98M/18.5M [00:06<00:12, 1.25MB/s]
     17%|██████▎                              | 3.18M/18.5M [00:06<00:11, 1.34MB/s]
     18%|██████▋                              | 3.37M/18.5M [00:06<00:10, 1.39MB/s]
     19%|███████▏                             | 3.58M/18.5M [00:07<00:10, 1.49MB/s]
     21%|███████▌                             | 3.80M/18.5M [00:07<00:09, 1.56MB/s]
     22%|████████                             | 4.03M/18.5M [00:07<00:08, 1.65MB/s]
     23%|████████▌                            | 4.28M/18.5M [00:07<00:08, 1.74MB/s]
     24%|█████████                            | 4.54M/18.5M [00:07<00:07, 1.84MB/s]
     26%|█████████▌                           | 4.80M/18.5M [00:07<00:07, 1.92MB/s]
     27%|██████████▏                          | 5.09M/18.5M [00:07<00:06, 2.03MB/s]
     29%|██████████▊                          | 5.38M/18.5M [00:07<00:06, 2.13MB/s]
     31%|███████████▍                         | 5.70M/18.5M [00:08<00:05, 2.24MB/s]
     33%|████████████                         | 6.02M/18.5M [00:08<00:05, 2.35MB/s]
     34%|████████████▋                        | 6.37M/18.5M [00:08<00:04, 2.46MB/s]
     36%|█████████████▍                       | 6.73M/18.5M [00:08<00:04, 2.58MB/s]
     38%|██████████████▏                      | 7.10M/18.5M [00:08<00:04, 2.70MB/s]
     41%|██████████████▉                      | 7.50M/18.5M [00:08<00:03, 2.85MB/s]
     43%|███████████████▊                     | 7.92M/18.5M [00:08<00:03, 2.99MB/s]
     45%|████████████████▋                    | 8.36M/18.5M [00:08<00:03, 3.14MB/s]
     48%|█████████████████▌                   | 8.82M/18.5M [00:09<00:02, 3.30MB/s]
     50%|██████████████████▌                  | 9.30M/18.5M [00:09<00:02, 3.46MB/s]
     53%|███████████████████▌                 | 9.82M/18.5M [00:09<00:02, 3.65MB/s]
     56%|████████████████████▋                | 10.4M/18.5M [00:09<00:02, 3.83MB/s]
     59%|█████████████████████▊               | 10.9M/18.5M [00:09<00:01, 4.02MB/s]
     62%|██████████████████████▉              | 11.5M/18.5M [00:09<00:01, 4.21MB/s]
     65%|████████████████████████▏            | 12.1M/18.5M [00:09<00:01, 4.43MB/s]
     69%|█████████████████████████▍           | 12.8M/18.5M [00:09<00:01, 4.65MB/s]
     73%|██████████████████████████▊          | 13.4M/18.5M [00:10<00:01, 4.88MB/s]
     76%|████████████████████████████▎        | 14.2M/18.5M [00:10<00:00, 5.13MB/s]
     80%|█████████████████████████████▊       | 14.9M/18.5M [00:10<00:00, 5.39MB/s]
     85%|███████████████████████████████▎     | 15.7M/18.5M [00:10<00:00, 5.64MB/s]
     89%|████████████████████████████████▉    | 16.5M/18.5M [00:10<00:00, 5.91MB/s]
     94%|██████████████████████████████████▋  | 17.4M/18.5M [00:10<00:00, 6.22MB/s]
     99%|████████████████████████████████████▌| 18.3M/18.5M [00:10<00:00, 6.52MB/s]
      0%|                                              | 0.00/18.5M [00:00<?, ?B/s]    100%|█████████████████████████████████████| 18.5M/18.5M [00:00<00:00, 28.6GB/s]
    009-2014-CrossSession: 100%|##########| 3/3 [00:27<00:00, 11.15s/it]    009-2014-CrossSession: 100%|##########| 3/3 [00:27<00:00,  9.14s/it]




.. GENERATED FROM PYTHON SOURCE LINES 127-135

Advanced MNE Pipeline
---------------------

In some case, the MNE pipeline should have access to the original labels from
the dataset. This is the case for the XDAWN code of MNE. One could pass
`mne_labels` to evaluation in order to keep this label.
As an example, we will define a pipeline that computes an XDAWN filter, rescale,
then apply a logistic regression.

.. GENERATED FROM PYTHON SOURCE LINES 135-153

.. code-block:: default


    mne_adv = {}
    mne_adv["XDAWN LR"] = make_pipeline(
        Xdawn(n_components=5, reg="ledoit_wolf", correct_overlap=False),
        Vectorizer(),
        StandardScaler(),
        LogisticRegression(penalty="l1", solver="liblinear"),
    )
    adv_eval = CrossSessionEvaluation(
        paradigm=paradigm,
        datasets=datasets,
        suffix="examples",
        overwrite=True,
        return_epochs=True,
        mne_labels=True,
    )
    adv_res = mne_eval.process(mne_adv)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    009-2014-CrossSession:   0%|          | 0/3 [00:00<?, ?it/s]    009-2014-CrossSession:  33%|###3      | 1/3 [00:04<00:08,  4.04s/it]    009-2014-CrossSession:  67%|######6   | 2/3 [00:06<00:03,  3.34s/it]    009-2014-CrossSession: 100%|##########| 3/3 [00:12<00:00,  4.26s/it]    009-2014-CrossSession: 100%|##########| 3/3 [00:12<00:00,  4.08s/it]




.. GENERATED FROM PYTHON SOURCE LINES 154-160

Numpy-based Pipeline
--------------------

For the comparison, we will define a Numpy-based pipeline that relies on
pyriemann to estimate XDAWN-extended covariance matrices that are projected
on the tangent space and classified with a logistic regression.

.. GENERATED FROM PYTHON SOURCE LINES 160-175

.. code-block:: default


    sk_ppl = {}
    sk_ppl["RG LR"] = make_pipeline(
        XdawnCovariances(nfilter=5, estimator="lwf", xdawn_estimator="scm"),
        TangentSpace(),
        LogisticRegression(penalty="l1", solver="liblinear"),
    )
    sk_eval = CrossSessionEvaluation(
        paradigm=paradigm,
        datasets=datasets,
        suffix="examples",
        overwrite=True,
    )
    sk_res = sk_eval.process(sk_ppl)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    009-2014-CrossSession:   0%|          | 0/3 [00:00<?, ?it/s]    009-2014-CrossSession:  33%|###3      | 1/3 [00:05<00:10,  5.25s/it]    009-2014-CrossSession:  67%|######6   | 2/3 [00:10<00:05,  5.23s/it]    009-2014-CrossSession: 100%|##########| 3/3 [00:15<00:00,  5.23s/it]    009-2014-CrossSession: 100%|##########| 3/3 [00:15<00:00,  5.23s/it]




.. GENERATED FROM PYTHON SOURCE LINES 176-182

Combining Results
-----------------

Even if the results have been obtained by different evaluation processes, it
is possible to combine the resulting DataFrames to analyze and plot the
results.

.. GENERATED FROM PYTHON SOURCE LINES 182-185

.. code-block:: default


    all_res = pd.concat([mne_res, adv_res, sk_res])








.. GENERATED FROM PYTHON SOURCE LINES 186-187

We could compare the Euclidean and Riemannian performance using a `paired_plot`

.. GENERATED FROM PYTHON SOURCE LINES 187-190

.. code-block:: default


    paired_plot(all_res, "XDAWN LR", "RG LR")




.. image-sg:: /auto_examples/advanced_examples/images/sphx_glr_plot_mne_and_scikit_estimators_001.png
   :alt: plot mne and scikit estimators
   :srcset: /auto_examples/advanced_examples/images/sphx_glr_plot_mne_and_scikit_estimators_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 1100x850 with 1 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 191-193

All the results could be compared and statistical analysis could highlight the
differences between pipelines.

.. GENERATED FROM PYTHON SOURCE LINES 193-198

.. code-block:: default


    stats = compute_dataset_statistics(all_res)
    P, T = find_significant_differences(stats)
    summary_plot(P, T)
    plt.show()



.. image-sg:: /auto_examples/advanced_examples/images/sphx_glr_plot_mne_and_scikit_estimators_002.png
   :alt: Algorithm comparison
   :srcset: /auto_examples/advanced_examples/images/sphx_glr_plot_mne_and_scikit_estimators_002.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  57.029 seconds)


.. _sphx_glr_download_auto_examples_advanced_examples_plot_mne_and_scikit_estimators.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_mne_and_scikit_estimators.py <plot_mne_and_scikit_estimators.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_mne_and_scikit_estimators.ipynb <plot_mne_and_scikit_estimators.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
