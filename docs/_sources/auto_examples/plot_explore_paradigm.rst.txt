
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_explore_paradigm.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_explore_paradigm.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_explore_paradigm.py:


=======================
Explore Paradigm Object
=======================

A paradigm defines how the raw data will be converted to trials ready
to be processed by a decoding algorithm. This is a function of the paradigm
used, i.e. in motor imagery one can have two-class, multi-class,
or continuous paradigms; similarly, different preprocessing is necessary
for ERP vs ERD paradigms.

A paradigm also defines the appropriate evaluation metric, for example AUC
for binary classification problem, accuracy for multiclass, or kappa
coefficient for continuous paradigms.

This tutorial explore the paradigm object, with 3 examples of paradigm :
     - MotorImagery
     - FilterBankMotorImagery
     - LeftRightImagery

.. GENERATED FROM PYTHON SOURCE LINES 22-34

.. code-block:: default

    # Authors: Alexandre Barachant <alexandre.barachant@gmail.com>
    #
    # License: BSD (3-clause)

    import numpy as np

    from moabb.datasets import BNCI2014001
    from moabb.paradigms import FilterBankMotorImagery, LeftRightImagery, MotorImagery


    print(__doc__)








.. GENERATED FROM PYTHON SOURCE LINES 35-39

MotorImagery
-----------------

First, lets take a example of the MotorImagery paradigm.

.. GENERATED FROM PYTHON SOURCE LINES 39-44

.. code-block:: default


    paradigm = MotorImagery(n_classes=4)

    print(paradigm.__doc__)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


        N-class motor imagery.

        Metric is 'roc-auc' if 2 classes and 'accuracy' if more

        Parameters
        -----------

        events: List of str
            event labels used to filter datasets (e.g. if only motor imagery is
            desired).

        n_classes: int,
            number of classes each dataset must have. If events is given,
            requires all imagery sorts to be within the events list.

        fmin: float (default 8)
            cutoff frequency (Hz) for the high pass filter

        fmax: float (default 32)
            cutoff frequency (Hz) for the low pass filter

        tmin: float (default 0.0)
            Start time (in second) of the epoch, relative to the dataset specific
            task interval e.g. tmin = 1 would mean the epoch will start 1 second
            after the begining of the task as defined by the dataset.

        tmax: float | None, (default None)
            End time (in second) of the epoch, relative to the begining of the
            dataset specific task interval. tmax = 5 would mean the epoch will end
            5 second after the begining of the task as defined in the dataset. If
            None, use the dataset value.

        baseline: None | tuple of length 2
                The time interval to consider as “baseline” when applying baseline
                correction. If None, do not apply baseline correction.
                If a tuple (a, b), the interval is between a and b (in seconds),
                including the endpoints.
                Correction is applied by computing the mean of the baseline period
                and subtracting it from the data (see mne.Epochs)

        channels: list of str | None (default None)
            list of channel to select. If None, use all EEG channels available in
            the dataset.

        resample: float | None (default None)
            If not None, resample the eeg data with the sampling rate provided.
    




.. GENERATED FROM PYTHON SOURCE LINES 45-48

The function `get_data` allow you to access preprocessed data from a dataset.
this function will return 3 objects. A numpy array containing the
preprocessed EEG data, the labels, and a dataframe with metadata.

.. GENERATED FROM PYTHON SOURCE LINES 48-51

.. code-block:: default


    print(paradigm.get_data.__doc__)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


            Return the data for a list of subject.

            return the data, labels and a dataframe with metadata. the dataframe
            will contain at least the following columns

            - subject : the subject indice
            - session : the session indice
            - run : the run indice

            parameters
            ----------
            dataset:
                A dataset instance.
            subjects: List of int
                List of subject number
            return_epochs: boolean
                This flag specifies whether to return only the data array or the
                complete processed mne.Epochs

            returns
            -------
            X : Union[np.ndarray, mne.Epochs]
                the data that will be used as features for the model
                Note: if return_epochs=True,  this is mne.Epochs
                if return_epochs=False, this is np.ndarray
            labels: np.ndarray
                the labels for training / evaluating the model
            metadata: pd.DataFrame
                A dataframe containing the metadata.
        




.. GENERATED FROM PYTHON SOURCE LINES 52-58

Lets take the example of the BNCI2014001 dataset, known as the dataset IIa
from the BCI competition IV. We will load the data from the subject 1.
When calling `get_data`, the paradigm will retrieve the data from the
specified list of subject, apply preprocessing (by default, a bandpass
between 7 and 35 Hz), epoch the data (with interval specified by the dataset,
unless superseeded by the paradigm) and return the corresponding objects.

.. GENERATED FROM PYTHON SOURCE LINES 58-64

.. code-block:: default


    dataset = BNCI2014001()
    subjects = [1]

    X, y, metadata = paradigm.get_data(dataset=dataset, subjects=subjects)








.. GENERATED FROM PYTHON SOURCE LINES 65-68

The epoched data is a 3D array, with epochs on the first dimension (here
576 trials), channels on the second (22 channels) and time sample on the last
one.

.. GENERATED FROM PYTHON SOURCE LINES 68-71

.. code-block:: default


    print(X.shape)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    (576, 22, 1001)




.. GENERATED FROM PYTHON SOURCE LINES 72-74

Labels contains the labels corresponding to each trial. in the case of this
dataset, we have the 4 type of motor imagery that was performed.

.. GENERATED FROM PYTHON SOURCE LINES 74-77

.. code-block:: default


    print(np.unique(y))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    ['feet' 'left_hand' 'right_hand' 'tongue']




.. GENERATED FROM PYTHON SOURCE LINES 78-86

metadata have at least 3 columns, subject, session and run.

- subject is the subject id of the corresponding trial
- session is the session id. A session is a all the data recorded without
  removing the EEG cap.
- run is the individual continuous recording made during a session. A Session
  may or may not contain multiple run.


.. GENERATED FROM PYTHON SOURCE LINES 86-90

.. code-block:: default



    print(metadata.head())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

       subject    session    run
    0        1  session_T  run_0
    1        1  session_T  run_0
    2        1  session_T  run_0
    3        1  session_T  run_0
    4        1  session_T  run_0




.. GENERATED FROM PYTHON SOURCE LINES 91-93

For this data, we have one subjecy, 2 sessions (2 different recording day)
and 6 run per session.

.. GENERATED FROM PYTHON SOURCE LINES 93-96

.. code-block:: default


    print(metadata.describe(include="all"))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

            subject    session    run
    count     576.0        576    576
    unique      NaN          2      6
    top         NaN  session_T  run_5
    freq        NaN        288     96
    mean        1.0        NaN    NaN
    std         0.0        NaN    NaN
    min         1.0        NaN    NaN
    25%         1.0        NaN    NaN
    50%         1.0        NaN    NaN
    75%         1.0        NaN    NaN
    max         1.0        NaN    NaN




.. GENERATED FROM PYTHON SOURCE LINES 97-99

Paradigm object can also return the list of all dataset compatible. here
it will return the list all the imagery datasets from the moabb.

.. GENERATED FROM PYTHON SOURCE LINES 99-103

.. code-block:: default


    compatible_datasets = paradigm.datasets
    print([dataset.code for dataset in compatible_datasets])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    ['Alexandre Motor Imagery', '001-2014', '002-2014', '004-2014', '001-2015', '004-2015', 'Cho2017', 'Lee2019_MI', 'Grosse-Wentrup 2009', 'Ofner2017', 'Physionet Motor Imagery', 'Schirrmeister2017', 'Shin2017A', 'Weibo 2014', 'Zhou 2016']




.. GENERATED FROM PYTHON SOURCE LINES 104-110

FilterBank MotorImagery
-----------------------

FilterBankMotorImagery is the same paradigm, but with a different
preprocessing. In this case, it apply a bank of 6 bandpass filter on the data
before concatenating the output.

.. GENERATED FROM PYTHON SOURCE LINES 110-115

.. code-block:: default


    paradigm = FilterBankMotorImagery()

    print(paradigm.__doc__)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


        Filter bank n-class motor imagery.

        Metric is 'roc-auc' if 2 classes and 'accuracy' if more

        Parameters
        -----------

        events: List of str
            event labels used to filter datasets (e.g. if only motor imagery is
            desired).

        n_classes: int,
            number of classes each dataset must have. If events is given,
            requires all imagery sorts to be within the events list.
    




.. GENERATED FROM PYTHON SOURCE LINES 116-117

therefore, the output X is a 4D array, with trial x channel x time x filter

.. GENERATED FROM PYTHON SOURCE LINES 117-122

.. code-block:: default


    X, y, metadata = paradigm.get_data(dataset=dataset, subjects=subjects)

    print(X.shape)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    (288, 22, 1001, 6)




.. GENERATED FROM PYTHON SOURCE LINES 123-128

LeftRight MotorImagery
----------------------

LeftRightImagery is a variation over the BaseMotorImagery paradigm,
restricted to left and right hand events.

.. GENERATED FROM PYTHON SOURCE LINES 128-133

.. code-block:: default


    paradigm = LeftRightImagery()

    print(paradigm.__doc__)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Motor Imagery for left hand/right hand classification

        Metric is 'roc_auc'

    




.. GENERATED FROM PYTHON SOURCE LINES 134-136

the compatible dataset list is a subset of motor imagery dataset that
contains at least left and right hand events.

.. GENERATED FROM PYTHON SOURCE LINES 136-140

.. code-block:: default


    compatible_datasets = paradigm.datasets
    print([dataset.code for dataset in compatible_datasets])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    ['001-2014', '004-2014', 'Cho2017', 'Lee2019_MI', 'Grosse-Wentrup 2009', 'Physionet Motor Imagery', 'Schirrmeister2017', 'Shin2017A', 'Weibo 2014', 'Zhou 2016']




.. GENERATED FROM PYTHON SOURCE LINES 141-143

So if we apply this this to our original dataset, it will only return trials
corresponding to left and right hand motor imagination.

.. GENERATED FROM PYTHON SOURCE LINES 143-147

.. code-block:: default


    X, y, metadata = paradigm.get_data(dataset=dataset, subjects=subjects)

    print(np.unique(y))




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    ['left_hand' 'right_hand']





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  15.396 seconds)


.. _sphx_glr_download_auto_examples_plot_explore_paradigm.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_explore_paradigm.py <plot_explore_paradigm.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_explore_paradigm.ipynb <plot_explore_paradigm.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
