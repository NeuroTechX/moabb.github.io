
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_benchmark_braindecode.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_benchmark_braindecode.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_benchmark_braindecode.py:


=======================================================================
Benchmarking on MOABB with Braindecode (PyTorch) deep net architectures
=======================================================================
This example shows how to use MOABB to benchmark a set of Braindecode pipelines (deep learning
architectures) on all available datasets.
For this example, we will use only 2 datasets to keep the computation time low, but this benchmark is designed
to easily scale to many datasets.

.. GENERATED FROM PYTHON SOURCE LINES 10-41

.. code-block:: default

    # Authors: Igor Carrara <igor.carrara@inria.fr>
    #          Bruno Aristimunha <b.aristimunha@gmail.com>
    #          Sylvain Chevallier <sylvain.chevallier@universite-paris-saclay.fr>
    #
    # License: BSD (3-clause)

    import os

    import matplotlib.pyplot as plt
    import torch
    from absl.logging import ERROR, set_verbosity

    from moabb import benchmark, set_log_level
    from moabb.analysis.plotting import score_plot
    from moabb.datasets import BNCI2014001, BNCI2014004
    from moabb.utils import setup_seed


    set_log_level("info")
    # Avoid output Warning
    set_verbosity(ERROR)
    os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"

    # Print Information PyTorch
    print(f"Torch Version: {torch.__version__}")

    # Set up GPU if it is there
    cuda = torch.cuda.is_available()
    device = "cuda" if cuda else "cpu"
    print("GPU is", "AVAILABLE" if cuda else "NOT AVAILABLE")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Torch Version: 1.13.1+cu117
    GPU is NOT AVAILABLE




.. GENERATED FROM PYTHON SOURCE LINES 42-66

In this example, we will use only 2 subjects from the dataset ``BNCI2014001`` and ``BNCI2014004``.

Running the benchmark
---------------------

The benchmark is run using the ``benchmark`` function. You need to specify the
folder containing the pipelines, the kind of evaluation, and the paradigm
to use. By default, the benchmark will use all available datasets for all
paradigms listed in the pipelines. You could restrict to specific evaluation and
paradigm using the ``evaluations`` and ``paradigms`` arguments.

To save computation time, the results are cached. If you want to re-run the
benchmark, you can set the ``overwrite`` argument to ``True``.

It is possible to indicate the folder to cache the results and the one to save
the analysis & figures. By default, the results are saved in the ``results``
folder, and the analysis & figures are saved in the ``benchmark`` folder.

This code is implemented to run on CPU. If you're using a GPU, do not use multithreading
(i.e. set n_jobs=1)

In order to allow the benchmark function to work with return_epoch=True (Required to use Braindecode(
we need to call each pipeline as "braindecode_xxx...", with xxx the name of the model to be
handled correctly by the benchmark function.

.. GENERATED FROM PYTHON SOURCE LINES 66-89

.. code-block:: default


    # Set up reproducibility of Tensorflow
    setup_seed(42)

    # Restrict this example only to the first two subjects of BNCI2014001
    dataset = BNCI2014001()
    dataset2 = BNCI2014004()
    dataset.subject_list = dataset.subject_list[:2]
    dataset2.subject_list = dataset2.subject_list[:2]
    datasets = [dataset, dataset2]

    results = benchmark(
        pipelines="./pipelines_braindecode",
        evaluations=["CrossSession"],
        paradigms=["LeftRightImagery"],
        include_datasets=datasets,
        results="./results/",
        overwrite=False,
        plot=False,
        output="./benchmark/",
        n_jobs=-1,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    001-2014-CrossSession:   0%|          | 0/2 [00:00<?, ?it/s]Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4688        0.6933       0.5172        0.6931  0.4561
          2       0.4531        0.6933       0.5172        0.6931  0.3799
          3       0.4531        0.6933       0.5172        0.6931  0.3926
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4062        0.6933       0.4828        0.6931  0.3332
          2       0.5000        0.6930       0.5172        0.6931  0.3635
          3       0.5156        0.6933       0.5172        0.6931  0.3591
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
    /home/runner/work/moabb/moabb/.venv/lib/python3.9/site-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)
      return F.conv2d(input, weight, bias, self.stride,
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.3438        0.7798       0.4828        0.6932  1.3684
          2       0.5469        0.7512       0.4828        0.6932  1.2176
          3       0.5625        0.7286       0.4828        0.6932  1.1564
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4688        0.7585       0.5172        0.6931  1.1328
          2       0.5938        0.6700       0.5172        0.6931  1.1149
          3       0.5469        0.7348       0.5172        0.6931  1.0248
          4       0.5000        0.7239       0.5172        0.6930  1.0232
          5       0.5156        0.7270       0.5172        0.6930  1.0182
          6       0.5312        0.7038       0.5172        0.6930  1.0790
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4688       27.7238       0.4828       23.0197  1.1689
          2       0.4219       25.3798       0.4828       19.5681  1.1615
          3       0.3594       20.9908       0.4828       16.1227  1.1306
          4       0.4531       16.6282       0.4828       12.7135  1.1309
          5       0.5156       13.1177       0.4828        9.4177  1.1248
          6       0.5312       11.1069       0.4828        6.2422  1.1344
          7       0.4219       15.1638       0.4828        3.1580  1.1236
          8       0.3906       12.4019       0.4828        0.7508  1.1212
          9       0.5469        8.5225       0.5172        1.8336  1.1230
         10       0.4531        8.7748       0.5172        3.7591  1.1233
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4531       13.2854       0.5172        0.9602  1.1133
          2       0.5938        7.8604       0.4828        1.0337  1.1228
          3       0.5312        9.7065       0.4828        2.1438  1.1216
    Stopping since valid_loss has not improved in the last 3 epochs.
    001-2014-CrossSession:  50%|#####     | 1/2 [00:47<00:47, 47.93s/it]Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5156        0.6931       0.5172        0.6931  0.3909
          2       0.5469        0.6929       0.5172        0.6931  0.3754
          3       0.5156        0.6932       0.5172        0.6931  0.3718
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5625        0.6927       0.5172        0.6931  0.3664
          2       0.5625        0.6931       0.5172        0.6931  0.3693
          3       0.6406        0.6924       0.4828        0.6932  0.3764
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5938        0.6882       0.5172        0.6931  1.0259
          2       0.6562        0.6543       0.5172        0.6931  0.9102
          3       0.6094        0.6568       0.5172        0.6931  1.0374
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4688        0.7668       0.4828        0.6932  0.9630
          2       0.4062        0.7538       0.4828        0.6933  0.9993
          3       0.5469        0.7062       0.4828        0.6933  1.0410
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4844       14.3689       0.5172        6.7214  1.1636
          2       0.5469       10.5937       0.5172        4.6868  1.1379
          3       0.5312        9.3564       0.5172        2.4372  1.1440
          4       0.4531       12.7838       0.5172        0.7123  1.1413
          5       0.4531       10.4121       0.4828        2.0288  1.1366
          6       0.4531       12.3265       0.4828        4.2991  1.1363
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5469       22.5475       0.4828       21.0031  1.1513
          2       0.4844       20.9980       0.4828       17.5455  1.1303
          3       0.4844       16.7448       0.4828       14.1628  1.1298
          4       0.5469       16.8429       0.4828       10.8096  1.1368
          5       0.5000       14.8197       0.4828        7.4715  1.1371
          6       0.5625        9.8160       0.4828        4.2562  1.1394
          7       0.4219       13.6924       0.4828        1.2905  1.1332
          8       0.5625        9.2381       0.5172        1.4640  1.1298
          9       0.4844       11.6585       0.5172        3.5749  1.1470
    Stopping since valid_loss has not improved in the last 3 epochs.
    001-2014-CrossSession: 100%|##########| 2/2 [01:34<00:00, 47.36s/it]    001-2014-CrossSession: 100%|##########| 2/2 [01:34<00:00, 47.45s/it]
    004-2014-CrossSession:   0%|          | 0/2 [00:00<?, ?it/s]
      0%|                                              | 0.00/34.2M [00:00<?, ?B/s]
      0%|                                     | 8.19k/34.2M [00:00<08:33, 66.6kB/s]
      0%|                                      | 24.6k/34.2M [00:00<05:27, 105kB/s]
      0%|                                     | 35.8k/34.2M [00:00<05:49, 97.7kB/s]
      0%|                                     | 46.1k/34.2M [00:00<06:14, 91.3kB/s]
      0%|                                     | 56.3k/34.2M [00:00<06:28, 87.8kB/s]
      0%|                                      | 72.7k/34.2M [00:00<05:33, 102kB/s]
      0%|                                     | 82.9k/34.2M [00:00<05:57, 95.5kB/s]
      0%|                                     | 96.3k/34.2M [00:01<05:45, 98.8kB/s]
      0%|▏                                      | 113k/34.2M [00:01<05:13, 109kB/s]
      0%|▏                                      | 128k/34.2M [00:01<05:01, 113kB/s]
      0%|▏                                      | 144k/34.2M [00:01<04:48, 118kB/s]
      0%|▏                                      | 168k/34.2M [00:01<04:04, 139kB/s]
      1%|▏                                      | 184k/34.2M [00:01<04:08, 137kB/s]
      1%|▏                                      | 201k/34.2M [00:01<04:12, 135kB/s]
      1%|▎                                      | 224k/34.2M [00:01<03:45, 151kB/s]
      1%|▎                                      | 249k/34.2M [00:02<03:26, 164kB/s]
      1%|▎                                      | 272k/34.2M [00:02<03:18, 171kB/s]
      1%|▎                                      | 296k/34.2M [00:02<03:12, 176kB/s]
      1%|▎                                      | 321k/34.2M [00:02<03:06, 182kB/s]
      1%|▍                                      | 344k/34.2M [00:02<03:04, 184kB/s]
      1%|▍                                      | 377k/34.2M [00:02<02:43, 207kB/s]
      1%|▍                                      | 409k/34.2M [00:02<02:33, 221kB/s]
      1%|▌                                      | 440k/34.2M [00:02<02:26, 230kB/s]
      1%|▌                                      | 472k/34.2M [00:03<02:22, 237kB/s]
      1%|▌                                      | 505k/34.2M [00:03<02:17, 244kB/s]
      2%|▌                                      | 537k/34.2M [00:03<02:16, 247kB/s]
      2%|▋                                      | 568k/34.2M [00:03<02:14, 249kB/s]
      2%|▋                                      | 608k/34.2M [00:03<02:04, 270kB/s]
      2%|▋                                      | 648k/34.2M [00:03<01:58, 284kB/s]
      2%|▊                                      | 688k/34.2M [00:03<01:53, 294kB/s]
      2%|▊                                      | 736k/34.2M [00:03<01:44, 321kB/s]
      2%|▉                                      | 784k/34.2M [00:04<01:38, 340kB/s]
      2%|▉                                      | 833k/34.2M [00:04<01:34, 352kB/s]
      3%|█                                      | 881k/34.2M [00:04<01:32, 362kB/s]
      3%|█                                      | 944k/34.2M [00:04<01:22, 405kB/s]
      3%|█                                     | 1.00M/34.2M [00:04<01:19, 418kB/s]
      3%|█▏                                    | 1.07M/34.2M [00:04<01:11, 464kB/s]
      3%|█▎                                    | 1.14M/34.2M [00:04<01:09, 479kB/s]
      4%|█▎                                    | 1.22M/34.2M [00:04<01:02, 526kB/s]
      4%|█▍                                    | 1.30M/34.2M [00:05<00:58, 559kB/s]
      4%|█▌                                    | 1.38M/34.2M [00:05<00:54, 601kB/s]
      4%|█▋                                    | 1.47M/34.2M [00:05<00:51, 631kB/s]
      5%|█▋                                    | 1.57M/34.2M [00:05<00:48, 671kB/s]
      5%|█▊                                    | 1.67M/34.2M [00:05<00:45, 718kB/s]
      5%|█▉                                    | 1.78M/34.2M [00:05<00:42, 770kB/s]
      6%|██                                    | 1.90M/34.2M [00:05<00:39, 825kB/s]
      6%|██▏                                   | 2.02M/34.2M [00:05<00:37, 863kB/s]
      6%|██▍                                   | 2.16M/34.2M [00:06<00:34, 930kB/s]
      7%|██▌                                   | 2.30M/34.2M [00:06<00:32, 993kB/s]
      7%|██▋                                  | 2.45M/34.2M [00:06<00:30, 1.04MB/s]
      8%|██▊                                  | 2.61M/34.2M [00:06<00:28, 1.11MB/s]
      8%|███                                  | 2.78M/34.2M [00:06<00:26, 1.17MB/s]
      9%|███▏                                 | 2.94M/34.2M [00:06<00:25, 1.23MB/s]
      9%|███▍                                 | 3.14M/34.2M [00:06<00:23, 1.32MB/s]
     10%|███▌                                 | 3.33M/34.2M [00:06<00:22, 1.38MB/s]
     10%|███▊                                 | 3.54M/34.2M [00:07<00:20, 1.46MB/s]
     11%|████                                 | 3.75M/34.2M [00:07<00:19, 1.54MB/s]
     12%|████▎                                | 3.98M/34.2M [00:07<00:18, 1.63MB/s]
     12%|████▌                                | 4.22M/34.2M [00:07<00:17, 1.72MB/s]
     13%|████▊                                | 4.47M/34.2M [00:07<00:16, 1.80MB/s]
     14%|█████                                | 4.74M/34.2M [00:07<00:15, 1.89MB/s]
     15%|█████▍                               | 5.02M/34.2M [00:07<00:14, 1.99MB/s]
     16%|█████▋                               | 5.31M/34.2M [00:07<00:13, 2.10MB/s]
     16%|██████                               | 5.62M/34.2M [00:08<00:13, 2.20MB/s]
     17%|██████▍                              | 5.94M/34.2M [00:08<00:12, 2.30MB/s]
     18%|██████▊                              | 6.28M/34.2M [00:08<00:11, 2.43MB/s]
     19%|███████▏                             | 6.63M/34.2M [00:08<00:10, 2.55MB/s]
     20%|███████▌                             | 7.00M/34.2M [00:08<00:10, 2.67MB/s]
     22%|███████▉                             | 7.39M/34.2M [00:08<00:09, 2.81MB/s]
     23%|████████▍                            | 7.81M/34.2M [00:08<00:08, 2.94MB/s]
     24%|████████▉                            | 8.23M/34.2M [00:08<00:08, 3.09MB/s]
     25%|█████████▍                           | 8.69M/34.2M [00:09<00:07, 3.25MB/s]
     27%|█████████▉                           | 9.17M/34.2M [00:09<00:07, 3.41MB/s]
     28%|██████████▍                          | 9.66M/34.2M [00:09<00:06, 3.59MB/s]
     30%|███████████                          | 10.2M/34.2M [00:09<00:06, 3.78MB/s]
     31%|███████████▌                         | 10.7M/34.2M [00:09<00:05, 3.95MB/s]
     33%|████████████▏                        | 11.3M/34.2M [00:09<00:05, 4.15MB/s]
     35%|████████████▉                        | 11.9M/34.2M [00:09<00:05, 4.34MB/s]
     37%|█████████████▌                       | 12.6M/34.2M [00:09<00:04, 4.57MB/s]
     39%|██████████████▎                      | 13.2M/34.2M [00:10<00:04, 4.80MB/s]
     41%|███████████████                      | 13.9M/34.2M [00:10<00:04, 5.02MB/s]
     43%|███████████████▊                     | 14.7M/34.2M [00:10<00:03, 5.28MB/s]
     45%|████████████████▋                    | 15.4M/34.2M [00:10<00:03, 5.55MB/s]
     48%|█████████████████▌                   | 16.2M/34.2M [00:10<00:03, 5.81MB/s]
     50%|██████████████████▌                  | 17.1M/34.2M [00:10<00:02, 6.11MB/s]
     53%|███████████████████▍                 | 18.0M/34.2M [00:10<00:02, 6.42MB/s]
     55%|████████████████████▍                | 18.9M/34.2M [00:10<00:02, 6.75MB/s]
     58%|█████████████████████▌               | 19.9M/34.2M [00:11<00:02, 7.10MB/s]
     61%|██████████████████████▋              | 21.0M/34.2M [00:11<00:01, 7.44MB/s]
     64%|███████████████████████▊             | 22.1M/34.2M [00:11<00:01, 7.80MB/s]
     68%|█████████████████████████            | 23.2M/34.2M [00:11<00:01, 8.20MB/s]
     71%|██████████████████████████▍          | 24.4M/34.2M [00:11<00:01, 8.59MB/s]
     75%|███████████████████████████▋         | 25.6M/34.2M [00:11<00:00, 9.01MB/s]
     79%|█████████████████████████████▏       | 27.0M/34.2M [00:11<00:00, 9.48MB/s]
     83%|██████████████████████████████▋      | 28.4M/34.2M [00:11<00:00, 9.95MB/s]
     87%|████████████████████████████████▏    | 29.8M/34.2M [00:12<00:00, 10.4MB/s]
     92%|█████████████████████████████████▉   | 31.3M/34.2M [00:12<00:00, 11.0MB/s]
     96%|███████████████████████████████████▋ | 32.9M/34.2M [00:12<00:00, 11.5MB/s]
      0%|                                              | 0.00/34.2M [00:00<?, ?B/s]    100%|█████████████████████████████████████| 34.2M/34.2M [00:00<00:00, 51.8GB/s]

      0%|                                              | 0.00/18.6M [00:00<?, ?B/s]
      0%|                                     | 8.19k/18.6M [00:00<04:53, 63.4kB/s]
      0%|                                     | 24.6k/18.6M [00:00<03:08, 98.4kB/s]
      0%|                                     | 34.8k/18.6M [00:00<03:28, 89.0kB/s]
      0%|                                     | 44.0k/18.6M [00:00<03:45, 82.1kB/s]
      0%|                                     | 56.3k/18.6M [00:00<03:36, 85.7kB/s]
      0%|▏                                    | 72.7k/18.6M [00:00<03:07, 99.0kB/s]
      0%|▏                                    | 82.9k/18.6M [00:00<03:20, 92.5kB/s]
      1%|▏                                    | 96.3k/18.6M [00:01<03:15, 94.9kB/s]
      1%|▏                                      | 113k/18.6M [00:01<02:57, 104kB/s]
      1%|▎                                      | 128k/18.6M [00:01<02:50, 108kB/s]
      1%|▎                                      | 144k/18.6M [00:01<02:42, 114kB/s]
      1%|▎                                      | 161k/18.6M [00:01<02:37, 117kB/s]
      1%|▍                                      | 184k/18.6M [00:01<02:16, 135kB/s]
      1%|▍                                      | 201k/18.6M [00:01<02:18, 132kB/s]
      1%|▍                                      | 224k/18.6M [00:01<02:05, 146kB/s]
      1%|▌                                      | 249k/18.6M [00:02<01:55, 158kB/s]
      1%|▌                                      | 265k/18.6M [00:02<02:03, 149kB/s]
      2%|▌                                      | 296k/18.6M [00:02<01:45, 174kB/s]
      2%|▋                                      | 321k/18.6M [00:02<01:53, 161kB/s]
      2%|▋                                      | 352k/18.6M [00:02<01:39, 184kB/s]
      2%|▊                                      | 377k/18.6M [00:02<01:38, 184kB/s]
      2%|▊                                      | 409k/18.6M [00:02<01:30, 201kB/s]
      2%|▉                                      | 440k/18.6M [00:03<01:25, 213kB/s]
      3%|▉                                      | 472k/18.6M [00:03<01:22, 221kB/s]
      3%|█                                      | 505k/18.6M [00:03<01:18, 229kB/s]
      3%|█▏                                     | 545k/18.6M [00:03<01:11, 251kB/s]
      3%|█▏                                     | 577k/18.6M [00:03<01:12, 248kB/s]
      3%|█▎                                     | 616k/18.6M [00:03<01:08, 264kB/s]
      4%|█▍                                     | 665k/18.6M [00:03<01:00, 294kB/s]
      4%|█▍                                     | 705k/18.6M [00:03<01:00, 297kB/s]
      4%|█▌                                     | 761k/18.6M [00:04<00:53, 336kB/s]
      4%|█▋                                     | 808k/18.6M [00:04<00:51, 342kB/s]
      5%|█▊                                     | 864k/18.6M [00:04<00:48, 368kB/s]
      5%|█▉                                     | 921k/18.6M [00:04<00:45, 392kB/s]
      5%|██                                     | 984k/18.6M [00:04<00:41, 420kB/s]
      6%|██▏                                   | 1.06M/18.6M [00:04<00:38, 459kB/s]
      6%|██▎                                   | 1.14M/18.6M [00:04<00:35, 497kB/s]
      7%|██▍                                   | 1.22M/18.6M [00:05<00:32, 529kB/s]
      7%|██▋                                   | 1.30M/18.6M [00:05<00:30, 571kB/s]
      7%|██▊                                   | 1.39M/18.6M [00:05<00:28, 608kB/s]
      8%|███                                   | 1.50M/18.6M [00:05<00:26, 654kB/s]
      9%|███▎                                  | 1.60M/18.6M [00:05<00:24, 704kB/s]
      9%|███▍                                  | 1.71M/18.6M [00:05<00:22, 748kB/s]
     10%|███▊                                  | 1.84M/18.6M [00:05<00:20, 805kB/s]
     11%|████                                  | 1.97M/18.6M [00:05<00:19, 866kB/s]
     11%|████▎                                 | 2.10M/18.6M [00:06<00:17, 917kB/s]
     12%|████▌                                 | 2.25M/18.6M [00:06<00:16, 971kB/s]
     13%|████▊                                | 2.40M/18.6M [00:06<00:15, 1.03MB/s]
     14%|█████                                | 2.57M/18.6M [00:06<00:14, 1.10MB/s]
     15%|█████▍                               | 2.74M/18.6M [00:06<00:13, 1.17MB/s]
     16%|█████▊                               | 2.92M/18.6M [00:06<00:12, 1.22MB/s]
     17%|██████▏                              | 3.12M/18.6M [00:06<00:11, 1.31MB/s]
     18%|██████▌                              | 3.33M/18.6M [00:07<00:10, 1.39MB/s]
     19%|███████                              | 3.54M/18.6M [00:07<00:10, 1.47MB/s]
     20%|███████▍                             | 3.77M/18.6M [00:07<00:09, 1.54MB/s]
     22%|███████▉                             | 4.02M/18.6M [00:07<00:08, 1.64MB/s]
     23%|████████▍                            | 4.26M/18.6M [00:07<00:08, 1.72MB/s]
     24%|█████████                            | 4.54M/18.6M [00:07<00:07, 1.82MB/s]
     26%|█████████▌                           | 4.82M/18.6M [00:07<00:07, 1.91MB/s]
     27%|██████████▏                          | 5.11M/18.6M [00:07<00:06, 2.01MB/s]
     29%|██████████▊                          | 5.42M/18.6M [00:08<00:06, 2.10MB/s]
     31%|███████████▍                         | 5.74M/18.6M [00:08<00:05, 2.22MB/s]
     33%|████████████                         | 6.08M/18.6M [00:08<00:05, 2.32MB/s]
     35%|████████████▊                        | 6.44M/18.6M [00:08<00:04, 2.44MB/s]
     37%|█████████████▌                       | 6.82M/18.6M [00:08<00:04, 2.57MB/s]
     39%|██████████████▎                      | 7.21M/18.6M [00:08<00:04, 2.69MB/s]
     41%|███████████████▏                     | 7.62M/18.6M [00:08<00:03, 2.83MB/s]
     43%|████████████████                     | 8.06M/18.6M [00:08<00:03, 2.98MB/s]
     46%|████████████████▉                    | 8.52M/18.6M [00:09<00:03, 3.13MB/s]
     48%|█████████████████▉                   | 9.00M/18.6M [00:09<00:02, 3.28MB/s]
     51%|██████████████████▉                  | 9.50M/18.6M [00:09<00:02, 3.45MB/s]
     54%|███████████████████▉                 | 10.0M/18.6M [00:09<00:02, 3.62MB/s]
     57%|█████████████████████                | 10.6M/18.6M [00:09<00:02, 3.79MB/s]
     60%|██████████████████████▏              | 11.2M/18.6M [00:09<00:01, 4.28MB/s]
     62%|███████████████████████              | 11.6M/18.6M [00:09<00:01, 4.04MB/s]
     65%|████████████████████████▏            | 12.2M/18.6M [00:10<00:01, 4.12MB/s]
     69%|█████████████████████████▌           | 12.8M/18.6M [00:10<00:01, 4.40MB/s]
     73%|██████████████████████████▉          | 13.5M/18.6M [00:10<00:01, 4.67MB/s]
     77%|████████████████████████████▎        | 14.2M/18.6M [00:10<00:00, 4.93MB/s]
     81%|█████████████████████████████▊       | 15.0M/18.6M [00:10<00:00, 5.19MB/s]
     85%|███████████████████████████████▍     | 15.8M/18.6M [00:10<00:00, 5.47MB/s]
     89%|█████████████████████████████████    | 16.6M/18.6M [00:10<00:00, 5.73MB/s]
     94%|██████████████████████████████████▉  | 17.5M/18.6M [00:10<00:00, 6.04MB/s]
     99%|████████████████████████████████████▋| 18.4M/18.6M [00:11<00:00, 6.32MB/s]
      0%|                                              | 0.00/18.6M [00:00<?, ?B/s]    100%|█████████████████████████████████████| 18.6M/18.6M [00:00<00:00, 47.8GB/s]
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5179        0.6931       0.4250        0.6932  0.5366
          2       0.4866        0.6932       0.4250        0.6933  0.4926
          3       0.4866        0.6931       0.4250        0.6933  0.5060
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5022        0.6932       0.4667        0.6932  0.5080
          2       0.4777        0.6932       0.4667        0.6932  0.5173
          3       0.5045        0.6931       0.4667        0.6933  0.5137
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5201        0.6932       0.5089        0.6931  0.5115
          2       0.4754        0.6933       0.5089        0.6931  0.5119
          3       0.5134        0.6931       0.4911        0.6931  0.5061
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5045        0.6931       0.5446        0.6931  0.5113
          2       0.4777        0.6931       0.4554        0.6932  0.4955
          3       0.5089        0.6931       0.4554        0.6932  0.4943
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4821        0.6932       0.4464        0.6933  0.5042
          2       0.5067        0.6932       0.4464        0.6933  0.4997
          3       0.5089        0.6930       0.4464        0.6934  0.4993
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5335        0.7015       0.4250        0.6937  1.4248
          2       0.5067        0.7196       0.4250        0.6941  1.3974
          3       0.5156        0.7154       0.4250        0.6946  1.3757
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4911        0.7278       0.4667        0.6948  1.3861
          2       0.5246        0.7138       0.4667        0.6968  1.4088
          3       0.5737        0.6972       0.4667        0.6989  1.4228
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5179        0.7321       0.4911        0.6933  1.3907
          2       0.4621        0.7514       0.4911        0.6935  1.3910
          3       0.5000        0.7256       0.4911        0.6937  1.3952
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5201        0.7175       0.4554        0.6937  1.4129
          2       0.5424        0.7148       0.4554        0.6944  1.4023
          3       0.4777        0.7348       0.4554        0.6950  1.3961
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4576        0.7532       0.4464        0.6932  1.3859
          2       0.5045        0.7298       0.4464        0.6933  1.3947
          3       0.5112        0.7287       0.4464        0.6934  1.4183
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5424       11.0493       0.5750        3.7544  1.2517
          2       0.5089       10.1792       0.4250        1.6010  1.2193
          3       0.5112       10.7445       0.4250        3.2716  1.2279
          4       0.4911       10.4823       0.4250        1.8648  1.1850
          5       0.4866       10.6709       0.5750        1.2825  1.1826
          6       0.5201        8.6806       0.4250        2.2831  1.2519
          7       0.5022       10.2316       0.4250        0.8276  1.2057
          8       0.4821       10.8644       0.5750        0.7082  1.1584
          9       0.5379        9.8387       0.4250        1.7220  1.2368
         10       0.5022       10.4484       0.4250        1.1341  1.1741
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5335       13.8588       0.4667        2.8252  1.2597
          2       0.5201       11.5918       0.4667        8.3938  1.2114
          3       0.5268       11.1948       0.5333        1.8819  1.1814
          4       0.4911       11.4412       0.5333        2.6285  1.1799
          5       0.5268       10.7095       0.4667        0.8521  1.3417
          6       0.4754       10.6279       0.4667        2.1753  1.1761
          7       0.5067       11.3995       0.4667        0.8495  1.2273
          8       0.5357        9.9013       0.4667        0.8434  1.2615
          9       0.5112       10.5304       0.4667        0.7513  1.2422
         10       0.5000       10.7219       0.5333        0.8741  1.2185
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5491       10.0756       0.5089        6.5308  1.2465
          2       0.5179       10.8071       0.4911        1.0260  1.2197
          3       0.5112       10.7274       0.4911        4.5077  1.1591
          4       0.4777       11.5107       0.5089        0.8681  1.1930
          5       0.5089       10.3990       0.5089        3.2467  1.1496
          6       0.4732       11.5879       0.4911        0.9915  1.1997
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5112       21.2787       0.5446        4.9825  1.1968
          2       0.4442       13.7347       0.4554        9.5433  1.2366
          3       0.4777       14.2992       0.4554        4.5921  1.1893
          4       0.5112       10.4999       0.5446        2.9736  1.1991
          5       0.5201       10.7346       0.5446        2.0220  1.1618
          6       0.4955       12.3382       0.4554        2.0137  1.1755
          7       0.5134       11.2431       0.4554        1.8499  1.1626
          8       0.5000       11.1055       0.4554        1.4709  1.1839
          9       0.4754       11.5610       0.4554        1.1035  1.1094
         10       0.4933       10.2712       0.5446        2.0003  1.1739
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4777       12.9240       0.4464        5.8364  1.1342
          2       0.5089       11.0484       0.4464        3.5424  1.1696
          3       0.4933       11.1745       0.5536        2.3947  1.2065
          4       0.5000       10.0113       0.5536        0.6922  1.2093
          5       0.4844       11.7437       0.4464        3.6550  1.1901
          6       0.5558        9.4569       0.5536        0.9188  1.1593
    Stopping since valid_loss has not improved in the last 3 epochs.
    004-2014-CrossSession:  50%|#####     | 1/2 [02:56<02:56, 176.60s/it]
      0%|                                              | 0.00/33.1M [00:00<?, ?B/s]
      0%|                                     | 8.19k/33.1M [00:00<08:14, 66.8kB/s]
      0%|                                      | 24.6k/33.1M [00:00<05:20, 103kB/s]
      0%|                                     | 35.8k/33.1M [00:00<05:37, 98.0kB/s]
      0%|                                     | 46.1k/33.1M [00:00<06:01, 91.5kB/s]
      0%|                                     | 56.3k/33.1M [00:00<06:15, 87.9kB/s]
      0%|                                     | 72.7k/33.1M [00:00<06:00, 91.4kB/s]
      0%|                                      | 88.1k/33.1M [00:00<05:27, 101kB/s]
      0%|                                       | 104k/33.1M [00:01<05:00, 110kB/s]
      0%|▏                                      | 121k/33.1M [00:01<04:43, 116kB/s]
      0%|▏                                      | 136k/33.1M [00:01<04:39, 118kB/s]
      0%|▏                                      | 153k/33.1M [00:01<04:30, 122kB/s]
      1%|▏                                      | 176k/33.1M [00:01<03:52, 142kB/s]
      1%|▏                                      | 193k/33.1M [00:01<03:57, 138kB/s]
      1%|▎                                      | 216k/33.1M [00:01<03:34, 153kB/s]
      1%|▎                                      | 232k/33.1M [00:01<03:44, 146kB/s]
      1%|▎                                      | 256k/33.1M [00:02<03:26, 159kB/s]
      1%|▎                                      | 281k/33.1M [00:02<03:13, 170kB/s]
      1%|▎                                      | 304k/33.1M [00:02<03:07, 175kB/s]
      1%|▍                                      | 329k/33.1M [00:02<03:00, 181kB/s]
      1%|▍                                      | 360k/33.1M [00:02<02:41, 203kB/s]
      1%|▍                                      | 384k/33.1M [00:02<02:45, 198kB/s]
      1%|▍                                      | 417k/33.1M [00:02<02:30, 217kB/s]
      1%|▌                                      | 449k/33.1M [00:02<02:23, 228kB/s]
      1%|▌                                      | 480k/33.1M [00:03<02:18, 235kB/s]
      2%|▌                                      | 512k/33.1M [00:03<02:15, 241kB/s]
      2%|▋                                      | 545k/33.1M [00:03<02:10, 248kB/s]
      2%|▋                                      | 585k/33.1M [00:03<02:01, 268kB/s]
      2%|▋                                      | 625k/33.1M [00:03<01:54, 283kB/s]
      2%|▊                                      | 665k/33.1M [00:03<01:50, 293kB/s]
      2%|▊                                      | 705k/33.1M [00:03<01:47, 302kB/s]
      2%|▉                                      | 753k/33.1M [00:03<01:38, 327kB/s]
      2%|▉                                      | 801k/33.1M [00:04<01:33, 344kB/s]
      3%|█                                      | 849k/33.1M [00:04<01:30, 356kB/s]
      3%|█                                      | 904k/33.1M [00:04<01:24, 380kB/s]
      3%|█▏                                     | 961k/33.1M [00:04<01:19, 402kB/s]
      3%|█▏                                    | 1.02M/33.1M [00:04<01:13, 433kB/s]
      3%|█▎                                    | 1.09M/33.1M [00:04<01:09, 458kB/s]
      4%|█▎                                    | 1.16M/33.1M [00:04<01:04, 492kB/s]
      4%|█▍                                    | 1.24M/33.1M [00:04<00:59, 532kB/s]
      4%|█▌                                    | 1.31M/33.1M [00:05<00:57, 550kB/s]
      4%|█▌                                    | 1.41M/33.1M [00:05<00:51, 613kB/s]
      5%|█▋                                    | 1.50M/33.1M [00:05<00:49, 640kB/s]
      5%|█▊                                    | 1.60M/33.1M [00:05<00:45, 697kB/s]
      5%|█▉                                    | 1.70M/33.1M [00:05<00:42, 735kB/s]
      5%|██                                    | 1.82M/33.1M [00:05<00:39, 783kB/s]
      6%|██▏                                   | 1.94M/33.1M [00:05<00:37, 835kB/s]
      6%|██▎                                   | 2.06M/33.1M [00:05<00:34, 889kB/s]
      7%|██▌                                   | 2.20M/33.1M [00:06<00:32, 947kB/s]
      7%|██▋                                   | 2.34M/33.1M [00:06<00:30, 992kB/s]
      8%|██▊                                  | 2.49M/33.1M [00:06<00:28, 1.06MB/s]
      8%|██▉                                  | 2.65M/33.1M [00:06<00:27, 1.12MB/s]
      9%|███▏                                 | 2.82M/33.1M [00:06<00:25, 1.19MB/s]
      9%|███▎                                 | 3.00M/33.1M [00:06<00:23, 1.27MB/s]
     10%|███▌                                 | 3.18M/33.1M [00:06<00:22, 1.33MB/s]
     10%|███▊                                 | 3.38M/33.1M [00:06<00:21, 1.41MB/s]
     11%|████                                 | 3.59M/33.1M [00:07<00:19, 1.48MB/s]
     12%|████▎                                | 3.81M/33.1M [00:07<00:18, 1.56MB/s]
     12%|████▌                                | 4.04M/33.1M [00:07<00:17, 1.62MB/s]
     13%|████▊                                | 4.29M/33.1M [00:07<00:16, 1.72MB/s]
     14%|█████                                | 4.54M/33.1M [00:07<00:15, 1.82MB/s]
     15%|█████▍                               | 4.82M/33.1M [00:07<00:14, 1.92MB/s]
     15%|█████▋                               | 5.10M/33.1M [00:07<00:13, 2.01MB/s]
     16%|██████                               | 5.39M/33.1M [00:07<00:13, 2.12MB/s]
     17%|██████▍                              | 5.70M/33.1M [00:08<00:12, 2.23MB/s]
     18%|██████▊                              | 6.03M/33.1M [00:08<00:11, 2.34MB/s]
     19%|███████▏                             | 6.38M/33.1M [00:08<00:10, 2.46MB/s]
     20%|███████▌                             | 6.74M/33.1M [00:08<00:10, 2.59MB/s]
     22%|███████▉                             | 7.11M/33.1M [00:08<00:09, 2.76MB/s]
     23%|████████▍                            | 7.51M/33.1M [00:08<00:08, 2.84MB/s]
     24%|████████▊                            | 7.93M/33.1M [00:08<00:08, 3.03MB/s]
     25%|█████████▎                           | 8.37M/33.1M [00:08<00:07, 3.17MB/s]
     27%|█████████▉                           | 8.82M/33.1M [00:09<00:07, 3.32MB/s]
     28%|██████████▍                          | 9.31M/33.1M [00:09<00:06, 3.42MB/s]
     30%|██████████▉                          | 9.82M/33.1M [00:09<00:06, 3.67MB/s]
     31%|███████████▌                         | 10.4M/33.1M [00:09<00:05, 3.85MB/s]
     33%|████████████▏                        | 10.9M/33.1M [00:09<00:05, 3.96MB/s]
     35%|████████████▊                        | 11.5M/33.1M [00:09<00:05, 4.24MB/s]
     37%|█████████████▌                       | 12.1M/33.1M [00:09<00:04, 4.44MB/s]
     39%|██████████████▎                      | 12.8M/33.1M [00:09<00:04, 4.66MB/s]
     41%|███████████████                      | 13.4M/33.1M [00:10<00:04, 4.81MB/s]
     43%|███████████████▊                     | 14.2M/33.1M [00:10<00:03, 5.07MB/s]
     45%|████████████████▋                    | 14.9M/33.1M [00:10<00:03, 5.40MB/s]
     47%|█████████████████▌                   | 15.7M/33.1M [00:10<00:03, 5.66MB/s]
     50%|██████████████████▍                  | 16.5M/33.1M [00:10<00:02, 5.93MB/s]
     53%|███████████████████▍                 | 17.4M/33.1M [00:10<00:02, 6.15MB/s]
     55%|████████████████████▍                | 18.3M/33.1M [00:10<00:02, 6.48MB/s]
     58%|█████████████████████▌               | 19.2M/33.1M [00:10<00:02, 6.91MB/s]
     61%|██████████████████████▋              | 20.2M/33.1M [00:11<00:01, 7.23MB/s]
     64%|███████████████████████▊             | 21.3M/33.1M [00:11<00:01, 7.59MB/s]
     68%|█████████████████████████            | 22.4M/33.1M [00:11<00:01, 7.95MB/s]
     71%|██████████████████████████▎          | 23.6M/33.1M [00:11<00:01, 8.32MB/s]
     75%|███████████████████████████▋         | 24.8M/33.1M [00:11<00:00, 8.74MB/s]
     79%|█████████████████████████████▏       | 26.0M/33.1M [00:11<00:00, 9.18MB/s]
     83%|██████████████████████████████▋      | 27.4M/33.1M [00:11<00:00, 9.65MB/s]
     87%|████████████████████████████████▏    | 28.8M/33.1M [00:11<00:00, 10.1MB/s]
     92%|█████████████████████████████████▉   | 30.3M/33.1M [00:12<00:00, 10.6MB/s]
     96%|███████████████████████████████████▌ | 31.8M/33.1M [00:12<00:00, 11.1MB/s]
      0%|                                              | 0.00/33.1M [00:00<?, ?B/s]    100%|█████████████████████████████████████| 33.1M/33.1M [00:00<00:00, 47.4GB/s]

      0%|                                              | 0.00/16.5M [00:00<?, ?B/s]
      0%|                                     | 8.19k/16.5M [00:00<04:19, 63.8kB/s]
      0%|                                      | 24.6k/16.5M [00:00<02:45, 100kB/s]
      0%|                                     | 34.8k/16.5M [00:00<03:03, 89.8kB/s]
      0%|                                     | 44.0k/16.5M [00:00<03:21, 81.9kB/s]
      0%|▏                                    | 56.3k/16.5M [00:00<03:11, 86.0kB/s]
      0%|▏                                    | 72.7k/16.5M [00:00<02:46, 99.1kB/s]
      1%|▏                                    | 82.9k/16.5M [00:00<02:58, 92.1kB/s]
      1%|▏                                    | 96.3k/16.5M [00:01<02:53, 95.0kB/s]
      1%|▎                                      | 113k/16.5M [00:01<02:37, 104kB/s]
      1%|▎                                      | 128k/16.5M [00:01<02:32, 108kB/s]
      1%|▎                                      | 144k/16.5M [00:01<02:25, 113kB/s]
      1%|▍                                      | 168k/16.5M [00:01<02:03, 133kB/s]
      1%|▍                                      | 184k/16.5M [00:01<02:05, 130kB/s]
      1%|▍                                      | 201k/16.5M [00:01<02:07, 129kB/s]
      1%|▌                                      | 224k/16.5M [00:01<01:53, 144kB/s]
      2%|▌                                      | 249k/16.5M [00:02<01:43, 157kB/s]
      2%|▋                                      | 272k/16.5M [00:02<01:39, 163kB/s]
      2%|▋                                      | 296k/16.5M [00:02<01:36, 168kB/s]
      2%|▊                                      | 321k/16.5M [00:02<01:33, 174kB/s]
      2%|▊                                      | 344k/16.5M [00:02<01:32, 175kB/s]
      2%|▉                                      | 377k/16.5M [00:02<01:21, 198kB/s]
      2%|▉                                      | 400k/16.5M [00:02<01:23, 193kB/s]
      3%|█                                      | 432k/16.5M [00:03<01:17, 207kB/s]
      3%|█                                      | 465k/16.5M [00:03<01:12, 220kB/s]
      3%|█▏                                     | 497k/16.5M [00:03<01:10, 226kB/s]
      3%|█▎                                     | 537k/16.5M [00:03<01:04, 249kB/s]
      3%|█▎                                     | 577k/16.5M [00:03<01:00, 265kB/s]
      4%|█▍                                     | 608k/16.5M [00:03<01:01, 259kB/s]
      4%|█▌                                     | 648k/16.5M [00:03<00:58, 272kB/s]
      4%|█▋                                     | 696k/16.5M [00:03<00:52, 300kB/s]
      5%|█▊                                     | 744k/16.5M [00:04<00:49, 319kB/s]
      5%|█▊                                     | 793k/16.5M [00:04<00:47, 333kB/s]
      5%|██                                     | 849k/16.5M [00:04<00:43, 362kB/s]
      5%|██▏                                    | 904k/16.5M [00:04<00:41, 379kB/s]
      6%|██▎                                    | 969k/16.5M [00:04<00:37, 413kB/s]
      6%|██▍                                   | 1.04M/16.5M [00:04<00:34, 452kB/s]
      7%|██▌                                   | 1.11M/16.5M [00:04<00:32, 480kB/s]
      7%|██▋                                   | 1.19M/16.5M [00:04<00:29, 518kB/s]
      8%|██▉                                   | 1.28M/16.5M [00:05<00:27, 563kB/s]
      8%|███▏                                  | 1.37M/16.5M [00:05<00:25, 595kB/s]
      9%|███▎                                  | 1.46M/16.5M [00:05<00:23, 635kB/s]
     10%|███▌                                  | 1.58M/16.5M [00:05<00:21, 699kB/s]
     10%|███▊                                  | 1.68M/16.5M [00:05<00:20, 728kB/s]
     11%|████▏                                 | 1.80M/16.5M [00:05<00:18, 783kB/s]
     12%|████▍                                 | 1.93M/16.5M [00:05<00:17, 840kB/s]
     12%|████▋                                 | 2.06M/16.5M [00:06<00:16, 898kB/s]
     13%|█████                                 | 2.21M/16.5M [00:06<00:14, 958kB/s]
     14%|█████▎                               | 2.36M/16.5M [00:06<00:13, 1.02MB/s]
     15%|█████▋                               | 2.52M/16.5M [00:06<00:13, 1.08MB/s]
     16%|██████                               | 2.70M/16.5M [00:06<00:11, 1.15MB/s]
     17%|██████▍                              | 2.87M/16.5M [00:06<00:11, 1.21MB/s]
     19%|██████▊                              | 3.06M/16.5M [00:06<00:10, 1.29MB/s]
     20%|███████▎                             | 3.26M/16.5M [00:06<00:09, 1.35MB/s]
     21%|███████▊                             | 3.48M/16.5M [00:07<00:09, 1.44MB/s]
     22%|████████▎                            | 3.70M/16.5M [00:07<00:08, 1.52MB/s]
     24%|████████▊                            | 3.94M/16.5M [00:07<00:07, 1.59MB/s]
     25%|█████████▍                           | 4.19M/16.5M [00:07<00:07, 1.70MB/s]
     27%|█████████▉                           | 4.45M/16.5M [00:07<00:06, 1.77MB/s]
     29%|██████████▌                          | 4.72M/16.5M [00:07<00:06, 1.87MB/s]
     30%|███████████▏                         | 5.02M/16.5M [00:07<00:05, 1.97MB/s]
     32%|███████████▉                         | 5.31M/16.5M [00:08<00:05, 2.07MB/s]
     34%|████████████▌                        | 5.63M/16.5M [00:08<00:05, 2.18MB/s]
     36%|█████████████▎                       | 5.97M/16.5M [00:08<00:04, 2.29MB/s]
     38%|██████████████▏                      | 6.32M/16.5M [00:08<00:04, 2.40MB/s]
     40%|██████████████▉                      | 6.69M/16.5M [00:08<00:03, 2.52MB/s]
     43%|███████████████▊                     | 7.07M/16.5M [00:08<00:03, 2.64MB/s]
     45%|████████████████▋                    | 7.48M/16.5M [00:08<00:03, 2.77MB/s]
     48%|█████████████████▋                   | 7.90M/16.5M [00:08<00:02, 2.91MB/s]
     51%|██████████████████▋                  | 8.35M/16.5M [00:09<00:02, 3.06MB/s]
     53%|███████████████████▋                 | 8.82M/16.5M [00:09<00:02, 3.21MB/s]
     56%|████████████████████▊                | 9.32M/16.5M [00:09<00:02, 3.38MB/s]
     60%|██████████████████████               | 9.84M/16.5M [00:09<00:01, 3.55MB/s]
     63%|███████████████████████▏             | 10.4M/16.5M [00:09<00:01, 3.70MB/s]
     66%|████████████████████████▌            | 11.0M/16.5M [00:09<00:01, 3.90MB/s]
     70%|█████████████████████████▊           | 11.6M/16.5M [00:09<00:01, 4.10MB/s]
     74%|███████████████████████████▏         | 12.2M/16.5M [00:09<00:01, 4.29MB/s]
     78%|████████████████████████████▋        | 12.8M/16.5M [00:10<00:00, 4.52MB/s]
     82%|██████████████████████████████▎      | 13.5M/16.5M [00:10<00:00, 4.73MB/s]
     86%|███████████████████████████████▉     | 14.3M/16.5M [00:10<00:00, 4.97MB/s]
     91%|█████████████████████████████████▌   | 15.0M/16.5M [00:10<00:00, 5.22MB/s]
     96%|███████████████████████████████████▍ | 15.8M/16.5M [00:10<00:00, 5.48MB/s]
      0%|                                              | 0.00/16.5M [00:00<?, ?B/s]    100%|█████████████████████████████████████| 16.5M/16.5M [00:00<00:00, 23.8GB/s]
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5067        0.6931       0.4286        0.6933  0.5117
          2       0.5201        0.6930       0.4286        0.6934  0.5162
          3       0.5179        0.6930       0.4286        0.6935  0.5052
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4933        0.6932       0.3929        0.6934  0.5191
          2       0.5201        0.6931       0.3929        0.6936  0.5124
          3       0.5312        0.6930       0.3929        0.6938  0.4923
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4870        0.6932       0.5096        0.6931  0.4350
          2       0.4635        0.6932       0.5096        0.6931  0.4262
          3       0.4792        0.6932       0.5096        0.6931  0.4342
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4911        0.6931       0.4196        0.6933  0.4965
          2       0.5022        0.6931       0.4196        0.6934  0.5129
          3       0.5179        0.6930       0.4196        0.6935  0.5305
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4922        0.6932       0.5096        0.6931  0.4331
          2       0.5000        0.6931       0.5096        0.6931  0.4403
          3       0.4766        0.6931       0.5096        0.6931  0.4401
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5759        0.6953       0.4286        0.6942  1.3751
          2       0.4911        0.7307       0.4286        0.6952  1.4103
          3       0.5268        0.7095       0.4286        0.6962  1.3929
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4978        0.7330       0.3929        0.6932  1.3854
          2       0.4933        0.7355       0.6071        0.6931  1.3687
          3       0.5089        0.7253       0.6071        0.6929  1.3754
          4       0.5067        0.7219       0.6071        0.6927  1.3867
          5       0.4598        0.7523       0.6071        0.6924  1.3866
          6       0.5000        0.7251       0.6071        0.6923  1.3852
          7       0.5067        0.7262       0.6071        0.6921  1.3904
          8       0.4911        0.7241       0.6071        0.6918  1.3825
          9       0.5246        0.7151       0.6071        0.6914  1.4244
         10       0.5201        0.7257       0.6071        0.6912  1.4182
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4349        0.7710       0.4904        0.6932  1.2151
          2       0.4479        0.7473       0.4904        0.6932  1.1974
          3       0.5339        0.7193       0.4904        0.6932  1.2159
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5000        0.7335       0.5804        0.6925  1.3824
          2       0.5112        0.7303       0.5804        0.6918  1.3923
          3       0.4978        0.7258       0.5804        0.6912  1.3719
          4       0.5156        0.7282       0.5804        0.6906  1.3680
          5       0.4911        0.7330       0.5804        0.6901  1.3824
          6       0.4933        0.7423       0.5804        0.6897  1.3610
          7       0.5067        0.7333       0.5804        0.6893  1.3838
          8       0.4598        0.7463       0.5804        0.6889  1.3682
          9       0.5045        0.7283       0.5804        0.6886  1.3695
         10       0.5268        0.7195       0.5804        0.6883  1.3944
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5391        0.7133       0.4904        0.6933  1.1952
          2       0.5026        0.7293       0.4904        0.6934  1.2228
          3       0.4635        0.7394       0.4904        0.6935  1.1866
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4554       13.7919       0.4286        5.0878  1.1526
          2       0.5089       10.0146       0.4286        5.7833  1.1789
          3       0.5156       10.0169       0.5714        2.2557  1.2814
          4       0.4866       10.3277       0.5714        0.6830  1.2035
          5       0.4933       11.4789       0.4286        3.7386  1.2508
          6       0.5000       10.6434       0.5714        1.6693  1.1650
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4777       11.5781       0.3929        2.2902  1.1778
          2       0.5000       10.4667       0.3929        2.5137  1.2104
          3       0.4866       10.6992       0.6071        0.6879  1.2026
          4       0.4777       11.0634       0.3929        4.0117  1.2245
          5       0.4754       12.2909       0.3929        0.8913  1.2035
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5443       10.0522       0.4904        3.1062  1.0309
          2       0.4948       11.4515       0.5096        0.9209  1.0317
          3       0.5078       12.2582       0.5096        1.2280  1.0998
          4       0.5208       10.5910       0.4904        0.9577  1.0337
    Stopping since valid_loss has not improved in the last 3 epochs.
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.4777       12.7330       0.5804        2.7648  1.2093
          2       0.4844       13.0894       0.5804        2.7496  1.1691
          3       0.4777       11.9441       0.4196        3.9712  1.1458
          4       0.5312       11.1100       0.4196        2.2121  1.2486
          5       0.4821       10.7821       0.5804        1.3499  1.2324
          6       0.4754       11.3505       0.4196        0.9696  1.1289
          7       0.5022       10.4662       0.4196        0.7427  1.1232
          8       0.5312        9.4586       0.5804        0.9615  1.2572
          9       0.5446        9.8984       0.4196        0.8478  1.1462
         10       0.5156       10.4911       0.4196        0.6979  1.2593
    Re-initializing module because the following parameters were re-set: module.
    Re-initializing criterion.
    Re-initializing optimizer.
      epoch    train_acc    train_loss    valid_acc    valid_loss     dur
    -------  -----------  ------------  -----------  ------------  ------
          1       0.5286       11.4544       0.4904        3.5658  1.0086
          2       0.5052       11.5136       0.4904        2.5173  1.0698
          3       0.4688       12.3420       0.5096        1.9070  1.0510
          4       0.4818       11.1149       0.4904        0.6980  0.9762
          5       0.4688       11.4455       0.5096        1.0166  1.0085
          6       0.4714       12.8390       0.4904        1.2014  1.0501
    Stopping since valid_loss has not improved in the last 3 epochs.
    004-2014-CrossSession: 100%|##########| 2/2 [05:49<00:00, 174.30s/it]    004-2014-CrossSession: 100%|##########| 2/2 [05:49<00:00, 174.64s/it]
        dataset    evaluation                     pipeline  avg score
    0  001-2014  CrossSession     braindecode_EEGInception   0.479962
    1  001-2014  CrossSession         braindecode_EEGNetv4   0.480638
    2  001-2014  CrossSession  braindecode_ShallowFBCSPNet   0.477648
    3  004-2014  CrossSession     braindecode_EEGInception   0.478361
    4  004-2014  CrossSession         braindecode_EEGNetv4   0.491451
    5  004-2014  CrossSession  braindecode_ShallowFBCSPNet   0.500000




.. GENERATED FROM PYTHON SOURCE LINES 90-100

The deep learning architectures implemented in MOABB using Braindecode are:

- Shallow Convolutional Network [1]_
- Deep Convolutional Network [1]_
- EEGNetv4 [2]_
- EEGInception [3]_

Benchmark prints a summary of the results. Detailed results are saved in a
pandas dataframe, and can be used to generate figures. The analysis & figures
are saved in the ``benchmark`` folder.

.. GENERATED FROM PYTHON SOURCE LINES 100-104

.. code-block:: default


    score_plot(results)
    plt.show()




.. image-sg:: /auto_examples/images/sphx_glr_plot_benchmark_braindecode_001.png
   :alt: Scores per dataset and algorithm
   :srcset: /auto_examples/images/sphx_glr_plot_benchmark_braindecode_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/runner/work/moabb/moabb/moabb/analysis/plotting.py:59: UserWarning: The palette list has more values (6) than needed (3), which may not be intended.
      sea.stripplot(




.. GENERATED FROM PYTHON SOURCE LINES 105-122

References
----------
.. [1] Schirrmeister, R. T., Springenberg, J. T., Fiederer, L. D. J.,
   Glasstetter, M., Eggensperger, K., Tangermann, M., ... & Ball, T. (2017).
   `Deep learning with convolutional neural networks for EEG decoding and
   visualization <https://doi.org/10.1002/hbm.23730>`_.
   Human brain mapping, 38(11), 5391-5420.
.. [2] Lawhern, V. J., Solon, A. J., Waytowich, N. R., Gordon, S. M.,
   Hung, C. P., & Lance, B. J. (2018). `EEGNet: a compact convolutional neural
   network for EEG-based brain-computer interfaces.
   <https://doi.org/10.1088/1741-2552/aace8c>`_
   Journal of neural engineering, 15(5), 056013.
.. [3] Santamaria-Vazquez, E., Martinez-Cagigal, V., Vaquerizo-Villar,
   F., & Hornero, R. (2020). `EEG-inception: A novel deep convolutional neural network
   for assistive ERP-based brain-computer interfaces.
   <https://doi.org/10.1109/TNSRE.2020.3048106>`_
   IEEE Transactions on Neural Systems and Rehabilitation Engineering


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 7 minutes  24.596 seconds)


.. _sphx_glr_download_auto_examples_plot_benchmark_braindecode.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_benchmark_braindecode.py <plot_benchmark_braindecode.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_benchmark_braindecode.ipynb <plot_benchmark_braindecode.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
